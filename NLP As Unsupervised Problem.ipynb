{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\jesst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download(\"gutenberg\")\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r\"--\", \" \", text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = gutenberg.paras(\"austen-emma.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Emma by Jane Austen 1816 ]', 'VOLUME I', 'CHAPTER I', 'Emma Woodhouse , handsome , clever , and rich , with a comfortable home and happy disposition , seemed to unite some of the best blessings of existence ; and had lived nearly twenty - one years in the world with very little to distress or vex her .']\n"
     ]
    }
   ],
   "source": [
    "emma_paras = []\n",
    "for paragraph in emma:\n",
    "    para = paragraph[0]\n",
    "    para = [re.sub(r\"--\", \"\", word) for word in para]\n",
    "    emma_paras.append(\" \".join(para))\n",
    "\n",
    "print(emma_paras[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma_paras_df = pd.DataFrame(emma_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Emma by Jane Austen 1816 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VOLUME I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAPTER I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma Woodhouse , handsome , clever , and rich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She was the youngest of the two daughters of a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                       [ Emma by Jane Austen 1816 ]\n",
       "1                                           VOLUME I\n",
       "2                                          CHAPTER I\n",
       "3  Emma Woodhouse , handsome , clever , and rich ...\n",
       "4  She was the youngest of the two daughters of a..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma_paras_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(emma_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.5, min_df=2,\n",
    "                            stop_words=\"english\",\n",
    "                            lowercase=True,\n",
    "                            use_idf=True,\n",
    "                            norm=u\"l2\",\n",
    "                            smooth_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1948\n"
     ]
    }
   ],
   "source": [
    "emma_paras_tfidf = vectorizer.fit_transform(emma_paras)\n",
    "print(\"Number of features: %d\" % emma_paras_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf= train_test_split(emma_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentenct: A very few minutes more , however , completed the present trial .\n",
      "Tf_idf vector: {'minutes': 0.7127450310382584, 'present': 0.701423210857947}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sentenct:\", X_train[5])\n",
    "print(\"Tf_idf vector:\", tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components 45.198152009443874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained = svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "\n",
    "print(\"Percent variance captured by all components\", total_variance*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0: \n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "Name: 0, dtype: float64\n",
      "Component 1: \n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.634779\n",
      "\" You get upon delicate subjects , Emma ,\" said Mrs . Weston smiling ; \" remember that I am here . Mr .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.586354\n",
      "\" I do not know what your opinion may be , Mrs . Weston ,\" said Mr . Knightley , \" of this great intimacy between Emma and Harriet Smith , but I think it a bad thing .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.561506\n",
      "\" You are right , Mrs . Weston ,\" said Mr . Knightley warmly , \" Miss Fairfax is as capable as any of us of forming a just opinion of Mrs . Elton .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.560199\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.528508\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.527676\n",
      "Emma found that it was not Mr . Weston ' s fault that the number of privy councillors was not yet larger .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.512677\n",
      "\" Now ,\" said Emma , when they were fairly beyond the sweep gates , \" now Mr . Weston , do let me know what has happened .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.509687\n",
      "\" In one respect , perhaps , Mr . Elton ' s manners are superior to Mr . Knightley ' s or Mr . Weston ' s .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.508500\n",
      "Mrs . Weston was acting no part , feigning no feelings in all that she said to him in favour of the event . She had been extremely surprized , never more so , than when Emma first opened the affair to her ; but she saw in it only increase of happiness to all , and had no scruple in urging him to the utmost . She had such a regard for Mr . Knightley , as to think he deserved even her dearest Emma ; and it was in every respect so proper , suitable , and unexceptionable a connexion , and in one respect , one point of the highest importance , so peculiarly eligible , so singularly fortunate , that now it seemed as if Emma could not safely have attached herself to any other creature , and that she had herself been the stupidest of beings in not having thought of it , and wished it long ago . How very few of those men in a rank of life to address Emma would have renounced their own home for Hartfield !    0.501504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 1, dtype: float64\n",
      "Component 2: \n",
      "CHAPTER I      0.998647\n",
      "CHAPTER V      0.998647\n",
      "CHAPTER I      0.998647\n",
      "CHAPTER I      0.998647\n",
      "CHAPTER X      0.998647\n",
      "CHAPTER X      0.998647\n",
      "CHAPTER V      0.998647\n",
      "CHAPTER V      0.998647\n",
      "CHAPTER X      0.998647\n",
      "CHAPTER XII    0.997554\n",
      "Name: 2, dtype: float64\n",
      "Component 3: \n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !\"     0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "But ah !    0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "Name: 3, dtype: float64\n",
      "Component 4: \n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .    0.650782\n",
      "Emma demurred .                                                                0.598770\n",
      "\" Are you well , my Emma ?\"                                                    0.598770\n",
      "Emma was silenced .                                                            0.587602\n",
      "At first it was downright dulness to Emma .                                    0.587085\n",
      "\" Emma , my dear Emma \"                                                        0.576868\n",
      "Emma could not resist .                                                        0.569573\n",
      "\" It is not now worth a regret ,\" said Emma .                                  0.557860\n",
      "\" For shame , Emma !                                                           0.531559\n",
      "\" No great variety of faces for you ,\" said Emma .                             0.490835\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "paras_by_component = pd.DataFrame(X_train_lsa, index=X_train)\n",
    "for i in range(5):\n",
    "    print(\"Component {}: \".format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: \n",
      "0 That is _court_ .\n",
      "1 \" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"\n",
      "2 \" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .\n",
      "3 To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .\n",
      "4 Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .\n",
      "5 A very few minutes more , however , completed the present trial .\n",
      "6 \" I am delighted to hear you speak so stoutly on the subject ,\" replied Emma , smiling ; \" but you do not mean to deny that there was a time  and not very distant either  when you gave me reason to understand that you did care about him ?\"\n",
      "7 \" Very well ; and if he had intended to give her one , he would have told her so .\"\n",
      "8 Some laughed , and answered good - humouredly .\n",
      "9 \" There appeared such a perfectly good understanding among them all \" he began rather quickly , but checking himself , added , \" however , it is impossible for me to say on what terms they really were  how it might all be behind the scenes .\n"
     ]
    }
   ],
   "source": [
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "\n",
    "sim_matrix = pd.DataFrame(similarity, index=X_train).iloc[:10,:10]\n",
    "\n",
    "ax = sns.heatmap(sim_matrix, yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "print(\"Key: \")\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>That is _court_ .</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.085559</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>-0.031076</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.029086</td>\n",
       "      <td>-0.129685</td>\n",
       "      <td>0.006908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "That is _court_ .  1.0 -0.164062 -0.085559  0.087338  0.004783 -0.031076   \n",
       "\n",
       "                          6         7         8         9  \n",
       "That is _court_ . -0.004805 -0.029086 -0.129685  0.006908  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix[sim_matrix[0] > .1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 0: Test Set\n",
    "Now it's your turn: Apply our LSA model to the test set. Does it identify similar sentences for components 0 through 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "lsa_trained = lsa.fit(X_train_tfidf)\n",
    "X_test_lsa = lsa.fit_transform(X_test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0: \n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "\" Oh !    0.999287\n",
      "Name: 0, dtype: float64\n",
      "Component 1: \n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.634779\n",
      "\" You get upon delicate subjects , Emma ,\" said Mrs . Weston smiling ; \" remember that I am here . Mr .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.586354\n",
      "\" I do not know what your opinion may be , Mrs . Weston ,\" said Mr . Knightley , \" of this great intimacy between Emma and Harriet Smith , but I think it a bad thing .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.561506\n",
      "\" You are right , Mrs . Weston ,\" said Mr . Knightley warmly , \" Miss Fairfax is as capable as any of us of forming a just opinion of Mrs . Elton .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.560199\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.528508\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.527676\n",
      "Emma found that it was not Mr . Weston ' s fault that the number of privy councillors was not yet larger .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.512677\n",
      "\" Now ,\" said Emma , when they were fairly beyond the sweep gates , \" now Mr . Weston , do let me know what has happened .\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.509687\n",
      "\" In one respect , perhaps , Mr . Elton ' s manners are superior to Mr . Knightley ' s or Mr . Weston ' s .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.508500\n",
      "Mrs . Weston was acting no part , feigning no feelings in all that she said to him in favour of the event . She had been extremely surprized , never more so , than when Emma first opened the affair to her ; but she saw in it only increase of happiness to all , and had no scruple in urging him to the utmost . She had such a regard for Mr . Knightley , as to think he deserved even her dearest Emma ; and it was in every respect so proper , suitable , and unexceptionable a connexion , and in one respect , one point of the highest importance , so peculiarly eligible , so singularly fortunate , that now it seemed as if Emma could not safely have attached herself to any other creature , and that she had herself been the stupidest of beings in not having thought of it , and wished it long ago . How very few of those men in a rank of life to address Emma would have renounced their own home for Hartfield !    0.501504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 1, dtype: float64\n",
      "Component 2: \n",
      "CHAPTER I      0.998647\n",
      "CHAPTER V      0.998647\n",
      "CHAPTER I      0.998647\n",
      "CHAPTER I      0.998647\n",
      "CHAPTER X      0.998647\n",
      "CHAPTER X      0.998647\n",
      "CHAPTER V      0.998647\n",
      "CHAPTER V      0.998647\n",
      "CHAPTER X      0.998647\n",
      "CHAPTER XII    0.997554\n",
      "Name: 2, dtype: float64\n",
      "Component 3: \n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !\"     0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "But ah !    0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "\" Ah !      0.992901\n",
      "Name: 3, dtype: float64\n",
      "Component 4: \n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .    0.650782\n",
      "Emma demurred .                                                                0.598770\n",
      "\" Are you well , my Emma ?\"                                                    0.598770\n",
      "Emma was silenced .                                                            0.587602\n",
      "At first it was downright dulness to Emma .                                    0.587085\n",
      "\" Emma , my dear Emma \"                                                        0.576868\n",
      "Emma could not resist .                                                        0.569573\n",
      "\" It is not now worth a regret ,\" said Emma .                                  0.557860\n",
      "\" For shame , Emma !                                                           0.531559\n",
      "\" No great variety of faces for you ,\" said Emma .                             0.490835\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_paras_by_component = pd.DataFrame(X_test_lsa, index=X_test)\n",
    "for i in range(5):\n",
    "    print(\"Component {}: \".format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFzpJREFUeJzt3Xu0XGV5x/HvLyc5JCQh4SaXBOQWxIjKJQ0oLWBBGsDCsktboMpFJK6liJfeULugYuuqN6hdBWsUFG8ggtYUU8ALUWoFEuViEoKGgHAM1xISuSbnnKd/7B06HM/Mnklmv2fPzu/D2it7Zva8zzsk55n3vPvd+1FEYGZmaYwb6w6YmW1NnHTNzBJy0jUzS8hJ18wsISddM7OEnHTNzBJy0jUza0LSFZIek7SsyeuS9K+SVkm6W9IhRW066ZqZNfdlYF6L148HZuXbfOBzRQ066ZqZNRERPwGebHHIycBXInMrMF3Sbq3aHN/NDo5m4xOrk1zyNnPfE1KESW78uL5ksfqU7jv4uaENSeJM75+SJA7AUAwnizVvyqxksa5be3eyWI+uW6ktbaOTnNO/877vIhuhbrIgIhZ0EG4G8FDD44H8uYebvaH0pGtmVlV5gu0kyY402pdEy6TvpGtm9TI8lDLaALBHw+OZwJpWb/CcrpnVy9Bg+9uWWwicnq9iOBxYFxFNpxbAI10zq5no4ty6pKuAo4GdJA0AFwITsjjx78Ai4ARgFfAscFZRm066ZlYvw91LuhFxasHrAbynkzaddM2sXhKuItkcTrpmVi9pT6R1zEnXzOql10e6kg4gu+piBtn6szXAwoi4p+S+mZl1LLqzKqE0LZeMSfo74GqyBcC3A0vy/asknV9+98zMOjQ83P42BopGumcDr4qIjY1PSroYWA7882hvkjSf/NK6yz7zj7zz9JYnAM3MuqfHpxeGgd2B34x4frf8tVE1XlqX6t4LZmZAz59Iez/wQ0m/5v9v6rAnsB9wbpkdMzPbLL080o2IGyTtD8wlO5EmsmuNl0REtb9OzGzrVPETaYWrFyK7pu7WBH0xM9tyY3SCrF1ep2tmtVL1X8KddM2sXnp5TtfMrOd4esHMLCGPdM3MEhraWHzMGHLSNbN62dqnF1JV6R24b1GSOKmlrHI8SLqzvuNGrefXfes3PJMkTmopK/T23M+WpxfMzBLa2ke6ZmZJOemamaUTPpFmZpaQ53TNzBLy9IKZWUIe6ZqZJeSRrplZQh7pmpklNFjtm5i3rAbciqSzutkRM7OuiOH2tzGw2UkX+GizFyTNl7RU0tLnNjy1BSHMzDrUyyXYJTW7wFvALs3e11gNeJdpB7gasJml0+NzursAfwKsHfG8gP8ppUdmZluix1cvXA9MiYg7R74gaXEpPTIz2xK9PNKNiLNbvHZa97tjZraF6rp6wcyskiLa3wpImifpXkmrJJ0/yut7SrpZ0h2S7pZUeANsJ10zq5curV6Q1AdcChwPzAZOlTR7xGF/D1wTEQcDpwCXFXXPF0eYWb1070TaXGBVRKwGkHQ1cDKwouGYALbL96cBa4oaddI1s3rp4ESapPnA/IanFuRLXgFmAA81vDYAHDaiiX8AbpL0XmAycGxRTCddM6uXofZr/TVeUzCK0Qr5jZwIPhX4ckR8RtLrgK9KOjCieeavzZxuygKOZlZh3bsibQDYo+HxTH5/+uBs4BqAiPgZMBHYqVWjtUm6PVex1MzK0b2kuwSYJWlvSf1kJ8oWjjjmQeAYAEmvJEu6j7dq1NMLZlYvXbo4IiIGJZ0L3Aj0AVdExHJJFwFLI2Ih8FfAFyR9gGzq4cyI1mvRnHTNrFZiuHu3e4mIRcCiEc9d0LC/AjiikzaddM2sXnr83gtmZr2lg9ULY8FJ18zqxSNdM7OEnHTNzBJq40Y2Y8lJ18zqpeIj3cKLIyQdIOkYSVNGPD+vvG6ZmW2m4Wh/GwMtk66k84DvAu8Flkk6ueHlj5fZMTOzzTI01P42BoqmF84BDo2IpyXtBVwraa+I+Cyj3wwCeOmde6ZO3IVJ/dO71F0zs9ai4tMLRUm3LyKeBoiIByQdTZZ4X06LpOtqwGY2ZsZo2qBdRXO6j0g6aNODPAG/iewuOq8us2NmZpslhtvfxkDRSPd04CVV3iJiEDhd0udL65WZ2eaq+Ei3qBrwQIvXftr97piZbaFBXwZsZpbOGE0btMtJ18zqpZenF8zMek2vLxkzM+stHumamSW0tSfd8eP6yg4B1LcacMqCmy/b67hksfr70nzfT0gUB+Ad2702WazLnlySLFbKn61H163c8kZ8E3Mzs3S6WSOtDE66ZlYvTrpmZgl59YKZWUIe6ZqZJeSka2aWTgx5esHMLB2PdM3M0vGSMTOzlHo96UqaC0RELJE0G5gHrIyIdJdKmZm1q9pTuq2TrqQLgeOB8ZK+DxwGLAbOl3RwRPxTk/e9WJhy2qTdmLzN9l3ttJlZMzFY7axbNNJ9C3AQsA3wCDAzItZL+hRwGzBq0m0sTDlj+1dVe6xvZvVS7ZxbmHQHI2IIeFbSfRGxHiAinpNU8Y9mZlujqp9IK6oGvEHStvn+oZuelDSNyn+fmNlWabiDrYCkeZLulbRK0vlNjvlzSSskLZf0jaI2i0a6R0bECwARLyk8NAE4o7jLZmZpdWukK6kPuBR4IzAALJG0MCJWNBwzC/gQcERErJX0sqJ2i6oBv9Dk+SeAJzrov5lZGt37HXwusCoiVgNIuho4GVjRcMw5wKURsRYgIh4rarRoesHMrKfEYPubpPmSljZs8xuamgE81PB4IH+u0f7A/pJ+KulWSfOK+ueLI8ysVjqpwN640moUGu0tIx6PB2YBRwMzgVskHRgRTzWL6ZGumdVL906kDQB7NDyeCawZ5ZjvRsTGiLgfuJcsCTflpGtmtRLD7W8FlgCzJO0tqR84BVg44pj/AN4AIGknsumG1a0a9fSCmdVKJ9MLLduJGJR0LnAj0AdcERHLJV0ELI2Ihflrx0laAQwBfxMR/9uqXUWUu5B4zx1enWSl8gtDG1OESW7D0GCyWI89cFOyWJN2/6MkcSb3T0wSB2D6NpOTxVr7/NPJYk0a358s1qPrVo42j9pZG0cf3XbO2WXx4i2O1ymPdM2sVro10i2Lk66Z1UoMJx+8dsRJ18xqxSNdM7OEIjzSNTNLxiNdM7OEhoc80jUzS8Yn0szMEqp60u34MmBJXymjI2Zm3RDR/jYWigpTjrzOWMAbJE0HiIiTyuqYmdnmqPpIt2h6YSbZDXu/SHZLMwFzgM+0elNjNeDtt92dKdvssOU9NTNrQ9WXjBVNL8wBfg58BFgXEYuB5yLixxHx42ZviogFETEnIuY44ZpZSkNDansbC0XleoaBSyR9K//z0aL3mJmNpaqPdNtKoBExALxV0onA+nK7ZGa2+Xp9TvclIuJ7wPdK6ouZ2RYbq1UJ7fJUgZnVSq1GumZmVTc0XO0qZE66ZlYrnl4wM0touA6rF8zMekUtloyZmfWKrX564bmhDWWHAGAc1f5221z9fem+F1NV6AV4bs0tSeLc/KoPJ4kDcOLaNJ8JYL/pM5LFevKF3lqa7+kFM7OEvHrBzCyhis8uOOmaWb14esHMLCGvXjAzS6jixYCddM2sXqLiK5mcdM2sVgY9vWBmlk6tRrqS/hCYCyyLiJvK6ZKZ2ear+pxuy1XEkm5v2D8H+DdgKnChpPNL7puZWccCtb2NhaJLNyY07M8H3hgRHwWOA/6y2ZskzZe0VNLS5zc81YVumpm1Z7iDrYikeZLulbSq1UBT0lskhaQ5RW0WJd1xkraXtCOgiHgcICKeAQabvamxGvDE/ulFfTAz65oh1PbWiqQ+4FLgeGA2cKqk2aMcNxU4D7itnf4VJd1pZCXYlwI7SNo1DzIFKj5bbWZbpWG1vxWYC6yKiNURsQG4Gjh5lOM+BnwSeL6d/rVMuhGxV0TsExF7538+sulzAW9uJ4CZWUrDqO2tcSo03+Y3NDUDeKjh8UD+3IskHQzsERHXt9u/zVoyFhHPAvdvznvNzMrUyQ1vImIBsKDJy6ONhV9sXtI44BLgzA5Cep2umdVLF5eMDQB7NDyeCaxpeDwVOBBYLAlgV2ChpJMiYmmzRp10zaxWhtW1001LgFmS9gZ+C5wCnLbpxYhYB+y06bGkxcBft0q44KRrZjUz1KV2ImJQ0rnAjUAfcEVELJd0EbA0IhZuTrtOumZWK22sSmhbRCwCFo147oImxx7dTptOumZWK8MVX81aetKd3j+l7BAvWr/hmWSxUpmQsDDl5P6JyWKlKhj5huUfTxIHYNo+85LF2rV/WrJYvVaY0uV6EqljwjWzznVzeqEMtUm6ZmZQ/buMOemaWa0MeaRrZpaOR7pmZgk56ZqZJVTxEmlOumZWLx7pmpkl1K3LgMvipGtmtVL1dbpFhSkPk7Rdvj9J0kcl/aekT0hKd0mMmVmbulkjrQxF5XquAJ7N9z9LVr7nE/lzXyqxX2Zmm6XqSbdoemFcRGwqQDknIg7J9/9b0p3N3pSXvJgPsPOUPZk2cadmh5qZdVXV771QNNJdJumsfP+uTeWFJe0PbGz2psZqwE64ZpZSFwtTlqIo6b4TOErSfWQliH8maTXwhfw1M7NKGepgGwstpxfychRn5nXd98mPH4iIR1N0zsysU8MVn2Boa8lYRPwOuKvkvpiZbTFfHGFmllC1x7lOumZWMx7pmpklNKhqj3WddM2sVqqdcp10zaxmtvrphaGo+v+CanvHdq9NFuvK3/0yWawT196SJE7KCr0Pr74hWay5B749WaxeU4slY2ZmvaLaKddJ18xqpuq/WzvpmlmtDFV8rOuka2a14pGumVlC4ZGumVk6HumamSXkJWNmZglVO+UW38TczKynDBJtb0UkzZN0r6RVks4f5fUPSloh6W5JP5T08qI2i6oBnydpj8KemZlVRHTwXyuS+oBLgePJKuecKmn2iMPuIKsf+RrgWuCTRf0rGul+DLhN0i2S3i1p56IG887Ol7RU0tL1zz/RzlvMzLqii9WA5wKrImJ1RGwArgZObjwgIm6OiE0V028FZhY1WpR0V+eNfAw4FFgh6QZJZ+QlfEbVWJhyOxemNLOEOhnpNg4Q821+Q1MzgIcaHg/kzzVzNvBfRf0rOpEWETEM3ATcJGkC2VD7VODTQFsjXzOzVDpZMhYRC4AFTV4erV7wqHMSkt4GzAGOKopZlHRfEjQiNgILgYWSJhU1bmaW2lB0bf3CANB4TmsmsGbkQZKOBT4CHBURLxQ1WpR0/6LZCxHxXFHjZmapdXGd7hJglqS9gd8CpwCnNR4g6WDg88C8iHisnUaLSrD/avP6amY2Nrp1GXBEDEo6F7gR6AOuiIjlki4ClkbEQuBTwBTgW5IAHoyIk1q164sjzKxWunkZcEQsAhaNeO6Chv1jO23TSdfMasWXAZuZJeS7jJmZJdTF1QulcNI1s1rZ6qcX5k2ZVXYIAK5be3eSOKld9uSSZLE2DA0mi7Xf9FYX9nTPrv3TksSBtBV6b1/21WSxZu57QrJY3eD76ZqZJeQ5XTOzhLb66QUzs5TCJ9LMzNJxCXYzs4Q8vWBmlpCnF8zMEvJI18wsoZ5eMiapn+wekmsi4geSTgNeD9wDLMhvam5mVhm9fhnwl/JjtpV0Btl9I78NHENWtO2McrtnZtaZXp9eeHVEvEbSeLI7p+8eEUOSvgbc1exNeXG3+QBH7XAos6fu07UOm5m1UvWkW1QNeFw+xTAV2BbYdCH7NsCEZm9qrAbshGtmKUVE29tYKBrpXg6sJCtV8RGykhSrgcPJasCbmVVK1Ue6RTXSLpH0zXx/jaSvAMcCX4iI21N00MysEz29egGyZNuw/xRwbak9MjPbAkNR7Zs7ep2umdWKr0gzM0uop+d0zcx6Tc/P6ZqZ9ZJhTy+YmaXjka6ZWUJVX72gss/07TLtgCRfOwP3LUoRJrleq8Rq9ZPyZ2vCTvtoS9vYf+c5beecXz2+dIvjdcojXTOrFU8vmJkl5BNpZmYJeaRrZpbQUAyNdRdactI1s1qp+mXARffTNTPrKcNE21sRSfMk3StplaTzR3l9G0nfzF+/TdJeRW066ZpZrXTrJuaS+oBLgeOB2cCpkmaPOOxsYG1E7AdcAnyiqH9OumZWK8MRbW8F5gKrImJ1RGwgK9xw8ohjTgauzPevBY6R1HLtb+GcrqR9gTcDewCDwK+BqyJiXdF7zcxS62T1QmM9x9yCiFiQ788AHmp4bQA4bEQTLx4TEYOS1gE7Ak80i1lUgv084E+BHwN/ANxJlnx/JundEbG44DOZmSXVyWXAeYJd0OTl0UasIzN6O8e8RNFI9xzgoLwC8MXAoog4WtLnge8CB4/a04Zvj6kTd2FS//SCMGZm3dHF1QsDZIPMTWYCa5ocM5BXTZ8GPNmq0XbmdDcl5m3IqgITEQ/SZjVgJ1wzS6mLc7pLgFmS9s6rop8CLBxxzELgjHz/LcCPoiDrF410vwgskXQrcCT5mTlJO1OQzc3MxkK3Rrr5HO25wI1kFdGviIjlki4ClkbEQrKK6V+VtIosJ55S1G5RNeDPSvoB8Erg4ohYmT//OFkSNjOrlG6W64mIRcCiEc9d0LD/PPDWTtpspxrwcmB5J42amY2Vql+R5suAzaxWqn4TcyddM6sV39rRzCwhTy+YmSXk++mamSXkka6ZWUJVn9Pt6DZoKTdgfp3iOFZvxarjZ6pzrF7aqnxrx/nFh/RUHMfqrVh1/Ex1jtUzqpx0zcxqx0nXzCyhKifdZve47NU4jtVbser4meocq2con/A2M7MEqjzSNTOrHSddM7OEKpd0i+rMdzHOFZIek7SsrBgNsfaQdLOkeyQtl/S+EmNNlHS7pLvyWB8tK1Yer0/SHZKuLznOA5J+KelOSUtLjjVd0rWSVuZ/Z68rKc4r8s+zaVsv6f0lxfpA/u9hmaSrJE0sI04e6315nOVlfZ6eNtYLhUcspu4D7gP2AfqBu4DZJcU6EjgEWJbgc+0GHJLvTwV+VeLnEjAl358A3AYcXuJn+yDwDeD6kv8fPgDsVPbfVR7rSuCd+X4/MD1BzD7gEeDlJbQ9A7gfmJQ/vgY4s6TPcSCwDNiW7IrXHwCzUvy99cpWtZFuO3XmuyIifkKikkMR8XBE/CLf/x1wD9kPQhmxIiKezh9OyLdSzpZKmgmcSFbWqRYkbUf2hXw5QERsiIinEoQ+BrgvIn5TUvvjgUl58cRt+f0Ci93ySuDWiHg2IgbJKom/uaRYPalqSXe0OvOlJKexImkvsirKt5UYo0/SncBjwPcjoqxY/wL8LZDirtEB3CTp53m16bLsAzwOfCmfNvmipMklxtvkFOCqMhqOiN8CnwYeBB4G1kXETWXEIhvlHilpR0nbAifw0oq6W72qJd2Oa8j3EklTgOuA90fE+rLiRMRQRBxEVjJ6rqQDux1D0puAxyLi591uu4kjIuIQ4HjgPZLKqtE3nmza6XMRcTDwDFDauQWAvNLsScC3Smp/e7LfGPcGdgcmS3pbGbEi4h6yArbfB24gmyIcLCNWr6pa0m2nznxPkjSBLOF+PSK+nSJm/mvxYmBeCc0fAZwk6QGyaaA/lvS1EuIAEBFr8j8fA75DNhVVhgFgoOG3g2vJknCZjgd+ERGPltT+scD9EfF4RGwEvg28vqRYRMTlEXFIRBxJNoX367Ji9aKqJd126sz3HEkimyO8JyIuLjnWzpKm5/uTyH7gVnY7TkR8KCJmRsReZH9PP4qIUkZPkiZLmrppHziO7NfYrouIR4CHJL0if+oYYEUZsRqcSklTC7kHgcMlbZv/WzyG7LxCKSS9LP9zT+DPKPez9ZxK3U83mtSZLyOWpKuAo4GdJA0AF0bE5WXEIhsVvh34ZT7XCvDhyMo7d9tuwJWS+si+VK+JiFKXcyWwC/CdLF8wHvhGRNxQYrz3Al/Pv/hXA2eVFSif93wj8K6yYkTEbZKuBX5B9qv+HZR7ie51knYENgLviYi1JcbqOb4M2MwsoapNL5iZ1ZqTrplZQk66ZmYJOemamSXkpGtmlpCTrplZQk66ZmYJ/R9OllxwZtfrvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: \n",
      "0 Mr . Woodhouse had so completely made up his mind to the visit , that in spite of the increasing coldness , he seemed to have no idea of shrinking from it , and set forward at last most punctually with his eldest daughter in his own carriage , with less apparent consciousness of the weather than either of the others ; too full of the wonder of his own going , and the pleasure it was to afford at Randalls to see that it was cold , and too well wrapt up to feel it .\n",
      "1 \" Oh !\n",
      "2 \" Oh no , no !\n",
      "3 Such was Jane Fairfax ' s history .\n",
      "4 \" That has been a good deal the case , my dear ; but not to the degree you mention .\n",
      "5 \" And I am quite serious too , I assure you ,\" replied Mrs . Elton gaily , \" in resolving to be always on the watch , and employing my friends to watch also , that nothing really unexceptionable may pass us .\"\n",
      "6 \" And here is Mrs . Weston and Mr . Frank Churchill too ! Quite delightful ; so many friends !\"\n",
      "7 \" You may well class the delight , the honour , and the comfort of such a situation together ,\" said Jane , \" they are pretty sure to be equal ; however , I am very serious in not wishing any thing to be attempted at present for me .\n",
      "8 Harriet , Mr . Elton , and Mr . Knightley , their own especial set , were the only persons invited to meet them ; the hours were to be early , as well as the numbers few ; Mr . Woodhouse ' s habits and inclination being consulted in every thing .\n",
      "9 \" Oh !\n"
     ]
    }
   ],
   "source": [
    "similarity = np.asarray(np.asmatrix(X_test_lsa) * np.asmatrix(X_test_lsa).T)\n",
    "\n",
    "sim_matrix = pd.DataFrame(similarity, index=X_test).iloc[:10,:10]\n",
    "\n",
    "ax = sns.heatmap(sim_matrix, yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "print(\"Key: \")\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>That is _court_ .</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.085559</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>-0.031076</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.029086</td>\n",
       "      <td>-0.129685</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065895</td>\n",
       "      <td>0.091305</td>\n",
       "      <td>-0.109623</td>\n",
       "      <td>-0.005330</td>\n",
       "      <td>-0.023722</td>\n",
       "      <td>0.238807</td>\n",
       "      <td>-0.065880</td>\n",
       "      <td>0.082840</td>\n",
       "      <td>0.050018</td>\n",
       "      <td>0.102223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"</th>\n",
       "      <td>-0.164062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.092416</td>\n",
       "      <td>-0.065668</td>\n",
       "      <td>-0.012093</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009222</td>\n",
       "      <td>-0.029894</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.004239</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>-0.003725</td>\n",
       "      <td>-0.018513</td>\n",
       "      <td>-0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .</th>\n",
       "      <td>-0.085559</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>-0.053455</td>\n",
       "      <td>-0.096431</td>\n",
       "      <td>0.039848</td>\n",
       "      <td>-0.074865</td>\n",
       "      <td>0.026413</td>\n",
       "      <td>0.036601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036538</td>\n",
       "      <td>-0.024235</td>\n",
       "      <td>0.038655</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>-0.023176</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>-0.031896</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.009799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .</th>\n",
       "      <td>0.087338</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.046690</td>\n",
       "      <td>0.077936</td>\n",
       "      <td>0.152790</td>\n",
       "      <td>0.156101</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185982</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>-0.003913</td>\n",
       "      <td>0.035248</td>\n",
       "      <td>0.063260</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.061470</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.177112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .</th>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>-0.053455</td>\n",
       "      <td>-0.046690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.028104</td>\n",
       "      <td>0.223867</td>\n",
       "      <td>0.288054</td>\n",
       "      <td>0.102717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183526</td>\n",
       "      <td>0.211410</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.004708</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.034299</td>\n",
       "      <td>-0.022114</td>\n",
       "      <td>0.050699</td>\n",
       "      <td>-0.017883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "That is _court_ .                                   1.000000 -0.164062   \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.164062  1.000000   \n",
       "\" How much his business engrosses him already i... -0.085559  0.004862   \n",
       "To restrain him as much as might be , by her ow...  0.087338  0.017256   \n",
       "Emma smiled and answered \" My visit was of use ...  0.004783  0.010669   \n",
       "\n",
       "                                                        2         3     \\\n",
       "That is _court_ .                                  -0.085559  0.087338   \n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.004862  0.017256   \n",
       "\" How much his business engrosses him already i...  1.000000  0.007822   \n",
       "To restrain him as much as might be , by her ow...  0.007822  1.000000   \n",
       "Emma smiled and answered \" My visit was of use ... -0.053455 -0.046690   \n",
       "\n",
       "                                                        4         5     \\\n",
       "That is _court_ .                                   0.004783 -0.031076   \n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.010669  0.000300   \n",
       "\" How much his business engrosses him already i... -0.053455 -0.096431   \n",
       "To restrain him as much as might be , by her ow... -0.046690  0.077936   \n",
       "Emma smiled and answered \" My visit was of use ...  1.000000  0.008106   \n",
       "\n",
       "                                                        6         7     \\\n",
       "That is _court_ .                                  -0.004805 -0.029086   \n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.092416 -0.065668   \n",
       "\" How much his business engrosses him already i...  0.039848 -0.074865   \n",
       "To restrain him as much as might be , by her ow...  0.152790  0.156101   \n",
       "Emma smiled and answered \" My visit was of use ...  0.028104  0.223867   \n",
       "\n",
       "                                                        8         9     \\\n",
       "That is _court_ .                                  -0.129685  0.006908   \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.012093  0.007839   \n",
       "\" How much his business engrosses him already i...  0.026413  0.036601   \n",
       "To restrain him as much as might be , by her ow...  0.018387  0.007282   \n",
       "Emma smiled and answered \" My visit was of use ...  0.288054  0.102717   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "That is _court_ .                                     ...     0.065895   \n",
       "\" Yes , sir , I did indeed ; and I am very much...    ...    -0.009222   \n",
       "\" How much his business engrosses him already i...    ...     0.036538   \n",
       "To restrain him as much as might be , by her ow...    ...     0.185982   \n",
       "Emma smiled and answered \" My visit was of use ...    ...     0.183526   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "That is _court_ .                                   0.091305 -0.109623   \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.029894  0.225653   \n",
       "\" How much his business engrosses him already i... -0.024235  0.038655   \n",
       "To restrain him as much as might be , by her ow...  0.027601 -0.003913   \n",
       "Emma smiled and answered \" My visit was of use ...  0.211410  0.000278   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "That is _court_ .                                  -0.005330 -0.023722   \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.028599 -0.004239   \n",
       "\" How much his business engrosses him already i...  0.061674  0.010940   \n",
       "To restrain him as much as might be , by her ow...  0.035248  0.063260   \n",
       "Emma smiled and answered \" My visit was of use ... -0.004708  0.033336   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "That is _court_ .                                   0.238807 -0.065880   \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.001085 -0.003493   \n",
       "\" How much his business engrosses him already i... -0.023176  0.019993   \n",
       "To restrain him as much as might be , by her ow...  0.039524  0.013807   \n",
       "Emma smiled and answered \" My visit was of use ...  0.001774  0.034299   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "That is _court_ .                                   0.082840  0.050018   \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.003725 -0.018513   \n",
       "\" How much his business engrosses him already i... -0.031896 -0.000018   \n",
       "To restrain him as much as might be , by her ow...  0.061470  0.036187   \n",
       "Emma smiled and answered \" My visit was of use ... -0.022114  0.050699   \n",
       "\n",
       "                                                        1421  \n",
       "That is _court_ .                                   0.102223  \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.009087  \n",
       "\" How much his business engrosses him already i...  0.009799  \n",
       "To restrain him as much as might be , by her ow...  0.177112  \n",
       "Emma smiled and answered \" My visit was of use ... -0.017883  \n",
       "\n",
       "[5 rows x 1422 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "\n",
    "sim_matrix2 = pd.DataFrame(similarity, index=X_train)\n",
    "\n",
    "sim_matrix2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.025836</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.029207</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.039617</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>0.013066</td>\n",
       "      <td>0.027628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056013</td>\n",
       "      <td>0.045278</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.017725</td>\n",
       "      <td>0.038361</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.038493</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.047438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.097199</td>\n",
       "      <td>0.086158</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>0.084324</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.079117</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>0.079255</td>\n",
       "      <td>0.083060</td>\n",
       "      <td>0.084706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099305</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>0.088351</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.091129</td>\n",
       "      <td>0.080325</td>\n",
       "      <td>0.086862</td>\n",
       "      <td>0.083660</td>\n",
       "      <td>0.103702</td>\n",
       "      <td>0.095443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.364799</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.130205</td>\n",
       "      <td>-0.151148</td>\n",
       "      <td>-0.264323</td>\n",
       "      <td>-0.233258</td>\n",
       "      <td>-0.130658</td>\n",
       "      <td>-0.245398</td>\n",
       "      <td>-0.129767</td>\n",
       "      <td>-0.263697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>-0.214901</td>\n",
       "      <td>-0.109623</td>\n",
       "      <td>-0.167771</td>\n",
       "      <td>-0.193410</td>\n",
       "      <td>-0.084063</td>\n",
       "      <td>-0.107891</td>\n",
       "      <td>-0.140567</td>\n",
       "      <td>-0.111657</td>\n",
       "      <td>-0.116567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.052511</td>\n",
       "      <td>-0.008769</td>\n",
       "      <td>-0.016768</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>-0.013039</td>\n",
       "      <td>-0.023160</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>-0.026552</td>\n",
       "      <td>-0.020760</td>\n",
       "      <td>-0.011523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002717</td>\n",
       "      <td>-0.004868</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>-0.018082</td>\n",
       "      <td>-0.010562</td>\n",
       "      <td>-0.010838</td>\n",
       "      <td>-0.006372</td>\n",
       "      <td>-0.012961</td>\n",
       "      <td>-0.010273</td>\n",
       "      <td>-0.007917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019404</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.007313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.052933</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>0.077643</td>\n",
       "      <td>0.050359</td>\n",
       "      <td>0.030312</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.034552</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.040658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091638</td>\n",
       "      <td>0.085178</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.031261</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.039598</td>\n",
       "      <td>0.017464</td>\n",
       "      <td>0.047922</td>\n",
       "      <td>0.077831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  1422.000000  1422.000000  1422.000000  1422.000000  1422.000000   \n",
       "mean     -0.002074     0.025836     0.008001     0.044966     0.029207   \n",
       "std       0.097199     0.086158     0.069452     0.084324     0.081815   \n",
       "min      -0.364799    -0.164062    -0.130205    -0.151148    -0.264323   \n",
       "25%      -0.052511    -0.008769    -0.016768    -0.005128    -0.013039   \n",
       "50%       0.001208     0.000000     0.000000     0.020496     0.008109   \n",
       "75%       0.052933     0.014362     0.019993     0.077643     0.050359   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              5            6            7            8            9     \\\n",
       "count  1422.000000  1422.000000  1422.000000  1422.000000  1422.000000   \n",
       "mean      0.012000     0.039617     0.010797     0.013066     0.027628   \n",
       "std       0.079117     0.083216     0.079255     0.083060     0.084706   \n",
       "min      -0.233258    -0.130658    -0.245398    -0.129767    -0.263697   \n",
       "25%      -0.023160    -0.005128    -0.026552    -0.020760    -0.011523   \n",
       "50%       0.000163     0.009991     0.000578     0.000000     0.003899   \n",
       "75%       0.030312     0.060167     0.034552     0.019971     0.040658   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...              1412         1413         1414         1415  \\\n",
       "count     ...       1422.000000  1422.000000  1422.000000  1422.000000   \n",
       "mean      ...          0.056013     0.045278     0.021604     0.017725   \n",
       "std       ...          0.099305     0.088591     0.088351     0.079519   \n",
       "min       ...         -0.130413    -0.214901    -0.109623    -0.167771   \n",
       "25%       ...         -0.002717    -0.004868    -0.011460    -0.018082   \n",
       "50%       ...          0.019404     0.019092     0.000000     0.000400   \n",
       "75%       ...          0.091638     0.085178     0.017669     0.031261   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              1416         1417         1418         1419         1420  \\\n",
       "count  1422.000000  1422.000000  1422.000000  1422.000000  1422.000000   \n",
       "mean      0.038361     0.010194     0.038493     0.014113     0.039391   \n",
       "std       0.091129     0.080325     0.086862     0.083660     0.103702   \n",
       "min      -0.193410    -0.084063    -0.107891    -0.140567    -0.111657   \n",
       "25%      -0.010562    -0.010838    -0.006372    -0.012961    -0.010273   \n",
       "50%       0.005761    -0.000447     0.003694     0.000000     0.003737   \n",
       "75%       0.053125     0.010117     0.039598     0.017464     0.047922   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              1421  \n",
       "count  1422.000000  \n",
       "mean      0.047438  \n",
       "std       0.095443  \n",
       "min      -0.116567  \n",
       "25%      -0.007917  \n",
       "50%       0.007313  \n",
       "75%       0.077831  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 1422 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>That is _court_ .</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.085559</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>-0.031076</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.029086</td>\n",
       "      <td>-0.129685</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065895</td>\n",
       "      <td>0.091305</td>\n",
       "      <td>-0.109623</td>\n",
       "      <td>-0.00533</td>\n",
       "      <td>-0.023722</td>\n",
       "      <td>0.238807</td>\n",
       "      <td>-0.06588</td>\n",
       "      <td>0.08284</td>\n",
       "      <td>0.050018</td>\n",
       "      <td>0.102223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5     \\\n",
       "That is _court_ .   1.0 -0.164062 -0.085559  0.087338  0.004783 -0.031076   \n",
       "\n",
       "                       6         7         8         9       ...         1412  \\\n",
       "That is _court_ . -0.004805 -0.029086 -0.129685  0.006908    ...     0.065895   \n",
       "\n",
       "                       1413      1414     1415      1416      1417     1418  \\\n",
       "That is _court_ .  0.091305 -0.109623 -0.00533 -0.023722  0.238807 -0.06588   \n",
       "\n",
       "                      1419      1420      1421  \n",
       "That is _court_ .  0.08284  0.050018  0.102223  \n",
       "\n",
       "[1 rows x 1422 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix2[sim_matrix2[0] > .33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"</th>\n",
       "      <td>-0.164062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.092416</td>\n",
       "      <td>-0.065668</td>\n",
       "      <td>-0.012093</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009222</td>\n",
       "      <td>-0.029894</td>\n",
       "      <td>0.225653</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-0.004239</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>-0.003725</td>\n",
       "      <td>-0.018513</td>\n",
       "      <td>-0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Both sir !</th>\n",
       "      <td>-0.165493</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003501</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.007640</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>-0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Have you indeed , sir ? Bless me !</th>\n",
       "      <td>-0.165493</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003501</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.007640</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>-0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" So very kind !\"</th>\n",
       "      <td>-0.111451</td>\n",
       "      <td>0.490915</td>\n",
       "      <td>-0.013119</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.065019</td>\n",
       "      <td>-0.020115</td>\n",
       "      <td>-0.024346</td>\n",
       "      <td>-0.053001</td>\n",
       "      <td>-0.021828</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>-0.033714</td>\n",
       "      <td>0.022521</td>\n",
       "      <td>-0.059082</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>-0.010244</td>\n",
       "      <td>-0.014253</td>\n",
       "      <td>-0.015404</td>\n",
       "      <td>-0.056194</td>\n",
       "      <td>0.007153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Not at all , sir .</th>\n",
       "      <td>-0.165493</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003501</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.007640</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>-0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Yes  I imagined  that is  I did not \"</th>\n",
       "      <td>-0.049902</td>\n",
       "      <td>0.527936</td>\n",
       "      <td>-0.011627</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.029558</td>\n",
       "      <td>0.164065</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>-0.026651</td>\n",
       "      <td>-0.023021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>-0.010235</td>\n",
       "      <td>0.385961</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>-0.022757</td>\n",
       "      <td>-0.016621</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>-0.010096</td>\n",
       "      <td>-0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Very well , I am much obliged to you .</th>\n",
       "      <td>-0.007904</td>\n",
       "      <td>0.518867</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>-0.017369</td>\n",
       "      <td>0.044637</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>-0.060169</td>\n",
       "      <td>-0.011426</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>-0.003756</td>\n",
       "      <td>-0.017182</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>-0.007825</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>-0.005942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.164062  1.000000   \n",
       "\" Both sir !                                       -0.165493  0.474239   \n",
       "\" Have you indeed , sir ? Bless me !               -0.165493  0.474239   \n",
       "\" So very kind !\"                                  -0.111451  0.490915   \n",
       "\" Not at all , sir .                               -0.165493  0.474239   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.049902  0.527936   \n",
       "\" Very well , I am much obliged to you .           -0.007904  0.518867   \n",
       "\n",
       "                                                        2         3     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.004862  0.017256   \n",
       "\" Both sir !                                        0.027467  0.002234   \n",
       "\" Have you indeed , sir ? Bless me !                0.027467  0.002234   \n",
       "\" So very kind !\"                                  -0.013119  0.012194   \n",
       "\" Not at all , sir .                                0.027467  0.002234   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.011627  0.003351   \n",
       "\" Very well , I am much obliged to you .           -0.000735  0.039640   \n",
       "\n",
       "                                                        4         5     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.010669  0.000300   \n",
       "\" Both sir !                                       -0.000924  0.002533   \n",
       "\" Have you indeed , sir ? Bless me !               -0.000924  0.002533   \n",
       "\" So very kind !\"                                   0.065019 -0.020115   \n",
       "\" Not at all , sir .                               -0.000924  0.002533   \n",
       "\" Yes  I imagined  that is  I did not \"             0.000007 -0.029558   \n",
       "\" Very well , I am much obliged to you .           -0.017369  0.044637   \n",
       "\n",
       "                                                        6         7     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.092416 -0.065668   \n",
       "\" Both sir !                                        0.001078  0.001037   \n",
       "\" Have you indeed , sir ? Bless me !                0.001078  0.001037   \n",
       "\" So very kind !\"                                  -0.024346 -0.053001   \n",
       "\" Not at all , sir .                                0.001078  0.001037   \n",
       "\" Yes  I imagined  that is  I did not \"             0.164065  0.006604   \n",
       "\" Very well , I am much obliged to you .            0.005667 -0.060169   \n",
       "\n",
       "                                                        8         9     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.012093  0.007839   \n",
       "\" Both sir !                                        0.002262 -0.005881   \n",
       "\" Have you indeed , sir ? Bless me !                0.002262 -0.005881   \n",
       "\" So very kind !\"                                  -0.021828  0.023437   \n",
       "\" Not at all , sir .                                0.002262 -0.005881   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.026651 -0.023021   \n",
       "\" Very well , I am much obliged to you .           -0.011426  0.002136   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...    ...    -0.009222   \n",
       "\" Both sir !                                          ...    -0.003501   \n",
       "\" Have you indeed , sir ? Bless me !                  ...    -0.003501   \n",
       "\" So very kind !\"                                     ...     0.001530   \n",
       "\" Not at all , sir .                                  ...    -0.003501   \n",
       "\" Yes  I imagined  that is  I did not \"               ...     0.012517   \n",
       "\" Very well , I am much obliged to you .              ...     0.003742   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.029894  0.225653   \n",
       "\" Both sir !                                        0.001472 -0.007640   \n",
       "\" Have you indeed , sir ? Bless me !                0.001472 -0.007640   \n",
       "\" So very kind !\"                                  -0.033714  0.022521   \n",
       "\" Not at all , sir .                                0.001472 -0.007640   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.010235  0.385961   \n",
       "\" Very well , I am much obliged to you .            0.006717  0.010340   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.028599 -0.004239   \n",
       "\" Both sir !                                        0.012017 -0.001285   \n",
       "\" Have you indeed , sir ? Bless me !                0.012017 -0.001285   \n",
       "\" So very kind !\"                                  -0.059082  0.031669   \n",
       "\" Not at all , sir .                                0.012017 -0.001285   \n",
       "\" Yes  I imagined  that is  I did not \"             0.021719 -0.022757   \n",
       "\" Very well , I am much obliged to you .           -0.003756 -0.017182   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.001085 -0.003493   \n",
       "\" Both sir !                                       -0.001483  0.002462   \n",
       "\" Have you indeed , sir ? Bless me !               -0.001483  0.002462   \n",
       "\" So very kind !\"                                  -0.010244 -0.014253   \n",
       "\" Not at all , sir .                               -0.001483  0.002462   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.016621  0.008519   \n",
       "\" Very well , I am much obliged to you .            0.006939  0.014886   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.003725 -0.018513   \n",
       "\" Both sir !                                       -0.002955  0.001966   \n",
       "\" Have you indeed , sir ? Bless me !               -0.002955  0.001966   \n",
       "\" So very kind !\"                                  -0.015404 -0.056194   \n",
       "\" Not at all , sir .                               -0.002955  0.001966   \n",
       "\" Yes  I imagined  that is  I did not \"             0.003878 -0.010096   \n",
       "\" Very well , I am much obliged to you .           -0.007825  0.008573   \n",
       "\n",
       "                                                        1421  \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.009087  \n",
       "\" Both sir !                                       -0.006209  \n",
       "\" Have you indeed , sir ? Bless me !               -0.006209  \n",
       "\" So very kind !\"                                   0.007153  \n",
       "\" Not at all , sir .                               -0.006209  \n",
       "\" Yes  I imagined  that is  I did not \"            -0.025206  \n",
       "\" Very well , I am much obliged to you .           -0.005942  \n",
       "\n",
       "[7 rows x 1422 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix2[sim_matrix2[1] > .47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .</th>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>-0.075318</td>\n",
       "      <td>0.059866</td>\n",
       "      <td>-0.039170</td>\n",
       "      <td>0.039267</td>\n",
       "      <td>-0.035098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>-0.020423</td>\n",
       "      <td>-0.056902</td>\n",
       "      <td>-0.008228</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>-0.008744</td>\n",
       "      <td>0.057532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That is _ship_ ; plain as it can be . Now for the cream .</th>\n",
       "      <td>0.009432</td>\n",
       "      <td>-0.020356</td>\n",
       "      <td>0.836338</td>\n",
       "      <td>0.099936</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>-0.032718</td>\n",
       "      <td>0.090459</td>\n",
       "      <td>-0.039912</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>-0.008964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044660</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>-0.017034</td>\n",
       "      <td>-0.082561</td>\n",
       "      <td>-0.043774</td>\n",
       "      <td>-0.004841</td>\n",
       "      <td>-0.015070</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>-0.011219</td>\n",
       "      <td>0.009273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" He is very plain , undoubtedly  remarkably plain : but that is nothing compared with his entire want of gentility .</th>\n",
       "      <td>0.026358</td>\n",
       "      <td>-0.007243</td>\n",
       "      <td>0.796838</td>\n",
       "      <td>0.062827</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.071085</td>\n",
       "      <td>-0.032224</td>\n",
       "      <td>0.027906</td>\n",
       "      <td>0.025476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061507</td>\n",
       "      <td>0.073437</td>\n",
       "      <td>-0.029287</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>-0.071702</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>-0.012649</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>-0.019250</td>\n",
       "      <td>0.010313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" You speak too plain .</th>\n",
       "      <td>-0.012510</td>\n",
       "      <td>-0.005114</td>\n",
       "      <td>0.679846</td>\n",
       "      <td>0.200839</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>0.040242</td>\n",
       "      <td>0.262069</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>-0.008825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056177</td>\n",
       "      <td>0.021692</td>\n",
       "      <td>-0.006445</td>\n",
       "      <td>-0.046617</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>-0.021793</td>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" My dear , you said that Miss Campbell would not allow him to be plain , and that you yourself \"</th>\n",
       "      <td>-0.080184</td>\n",
       "      <td>-0.017673</td>\n",
       "      <td>0.564266</td>\n",
       "      <td>0.050527</td>\n",
       "      <td>-0.016049</td>\n",
       "      <td>0.026401</td>\n",
       "      <td>0.051884</td>\n",
       "      <td>-0.036560</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>-0.014901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>-0.022994</td>\n",
       "      <td>-0.022859</td>\n",
       "      <td>-0.051495</td>\n",
       "      <td>-0.013322</td>\n",
       "      <td>-0.016998</td>\n",
       "      <td>0.093125</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.009813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" You are speaking of letters of business ; mine are letters of friendship .\"</th>\n",
       "      <td>0.068225</td>\n",
       "      <td>0.093377</td>\n",
       "      <td>0.511107</td>\n",
       "      <td>0.029770</td>\n",
       "      <td>-0.016202</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.045541</td>\n",
       "      <td>-0.053397</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.088047</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.029748</td>\n",
       "      <td>-0.011493</td>\n",
       "      <td>-0.027306</td>\n",
       "      <td>-0.043432</td>\n",
       "      <td>0.044016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "\" How much his business engrosses him already i...  0.003305  0.002378   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.009432 -0.020356   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.026358 -0.007243   \n",
       "\" You speak too plain .                            -0.012510 -0.005114   \n",
       "\" My dear , you said that Miss Campbell would n... -0.080184 -0.017673   \n",
       "\" You are speaking of letters of business ; min...  0.068225  0.093377   \n",
       "\n",
       "                                                        2         3     \\\n",
       "\" How much his business engrosses him already i...  1.000000  0.033688   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.836338  0.099936   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.796838  0.062827   \n",
       "\" You speak too plain .                             0.679846  0.200839   \n",
       "\" My dear , you said that Miss Campbell would n...  0.564266  0.050527   \n",
       "\" You are speaking of letters of business ; min...  0.511107  0.029770   \n",
       "\n",
       "                                                        4         5     \\\n",
       "\" How much his business engrosses him already i...  0.015647 -0.075318   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.008397 -0.032718   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.029657  0.004541   \n",
       "\" You speak too plain .                             0.036118  0.040242   \n",
       "\" My dear , you said that Miss Campbell would n... -0.016049  0.026401   \n",
       "\" You are speaking of letters of business ; min... -0.016202  0.007142   \n",
       "\n",
       "                                                        6         7     \\\n",
       "\" How much his business engrosses him already i...  0.059866 -0.039170   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.090459 -0.039912   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.071085 -0.032224   \n",
       "\" You speak too plain .                             0.262069 -0.015105   \n",
       "\" My dear , you said that Miss Campbell would n...  0.051884 -0.036560   \n",
       "\" You are speaking of letters of business ; min...  0.002161  0.045541   \n",
       "\n",
       "                                                        8         9     \\\n",
       "\" How much his business engrosses him already i...  0.039267 -0.035098   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.043067 -0.008964   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.027906  0.025476   \n",
       "\" You speak too plain .                             0.014351 -0.008825   \n",
       "\" My dear , you said that Miss Campbell would n...  0.011475 -0.014901   \n",
       "\" You are speaking of letters of business ; min... -0.053397  0.046215   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "\" How much his business engrosses him already i...    ...     0.011531   \n",
       "That is _ship_ ; plain as it can be . Now for t...    ...     0.044660   \n",
       "\" He is very plain , undoubtedly  remarkably pl...    ...     0.061507   \n",
       "\" You speak too plain .                               ...     0.056177   \n",
       "\" My dear , you said that Miss Campbell would n...    ...     0.096970   \n",
       "\" You are speaking of letters of business ; min...    ...     0.017918   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "\" How much his business engrosses him already i...  0.029968 -0.020423   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.033907 -0.017034   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.073437 -0.029287   \n",
       "\" You speak too plain .                             0.021692 -0.006445   \n",
       "\" My dear , you said that Miss Campbell would n... -0.022994 -0.022859   \n",
       "\" You are speaking of letters of business ; min...  0.088047 -0.005109   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "\" How much his business engrosses him already i... -0.056902 -0.008228   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.082561 -0.043774   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.040143 -0.071702   \n",
       "\" You speak too plain .                            -0.046617  0.008678   \n",
       "\" My dear , you said that Miss Campbell would n... -0.051495 -0.013322   \n",
       "\" You are speaking of letters of business ; min...  0.028493  0.018885   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "\" How much his business engrosses him already i...  0.002337  0.011103   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.004841 -0.015070   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.014093 -0.012649   \n",
       "\" You speak too plain .                             0.005874  0.006124   \n",
       "\" My dear , you said that Miss Campbell would n... -0.016998  0.093125   \n",
       "\" You are speaking of letters of business ; min...  0.029748 -0.011493   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "\" How much his business engrosses him already i... -0.004658 -0.008744   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.006436 -0.011219   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.016860 -0.019250   \n",
       "\" You speak too plain .                             0.002431 -0.021793   \n",
       "\" My dear , you said that Miss Campbell would n...  0.015848  0.015318   \n",
       "\" You are speaking of letters of business ; min... -0.027306 -0.043432   \n",
       "\n",
       "                                                        1421  \n",
       "\" How much his business engrosses him already i...  0.057532  \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.009273  \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.010313  \n",
       "\" You speak too plain .                             0.002911  \n",
       "\" My dear , you said that Miss Campbell would n...  0.009813  \n",
       "\" You are speaking of letters of business ; min...  0.044016  \n",
       "\n",
       "[6 rows x 1422 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix2[sim_matrix2[2] > .5].sort_values(2, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** In general, there wasn't a great deal of similarity when I pulled the sentences with the highest similarity scores. A couple of the sentences above were very similar, but most had just one word in common (for example, \"plain\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 1: Tweaking tf-idf\n",
    "Go back up to the code where we originally translated the text from words to numbers. There are a lot of decision-points here, from the stop list to the thresholds for inclusion and exclusion, and many others as well. We also didn't integrate spaCy, and so don't have info on lemmas or Named Entities. Change things up a few times and see how that affects the results of the LSA. Write up your observations and share them with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** The initial run had an explained variance percentage of 45.7%. When the min_df (minimum document frequency) was increased to .7 (70% of the documents had to contain it) and the max_df (maximum document frequency) was increased to 5, the percent explained variance was 55.8%. The contents of the components were rather similar with the exception of Component 4 that had fewer overlaps in documents. When I lowered the min_df to .2, the percent explained variance was 45.2% and the components were similar.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get it done:\n",
    "+ change the min and max df based on the similarity that i'm seeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>max_df is .2 and min_df is 2</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(emma_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.2, min_df=2,\n",
    "                            stop_words=\"english\",\n",
    "                            lowercase=True,\n",
    "                            use_idf=True,\n",
    "                            norm=u\"l2\",\n",
    "                            smooth_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1948\n"
     ]
    }
   ],
   "source": [
    "emma_paras_tfidf = vectorizer.fit_transform(emma_paras)\n",
    "print(\"Number of features: %d\" % emma_paras_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf= train_test_split(emma_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentenct: A very few minutes more , however , completed the present trial .\n",
      "Tf_idf vector: {'minutes': 0.7127450310382584, 'present': 0.701423210857947}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sentenct:\", X_train[5])\n",
    "print(\"Tf_idf vector:\", tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components 45.2027371682007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained = svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "\n",
    "print(\"Percent variance captured by all components\", total_variance*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0: \n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !     0.999289\n",
      "\" Oh !\"    0.999289\n",
      "\" Oh !     0.999289\n",
      "Name: 0, dtype: float64\n",
      "Component 1: \n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                                                                                0.634584\n",
      "\" You get upon delicate subjects , Emma ,\" said Mrs . Weston smiling ; \" remember that I am here . Mr .                                                                     0.564350\n",
      "\" I do not know what your opinion may be , Mrs . Weston ,\" said Mr . Knightley , \" of this great intimacy between Emma and Harriet Smith , but I think it a bad thing .\"    0.564148\n",
      "\" You are right , Mrs . Weston ,\" said Mr . Knightley warmly , \" Miss Fairfax is as capable as any of us of forming a just opinion of Mrs . Elton .                         0.562287\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                                                                                           0.529653\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .                                                                                                 0.528287\n",
      "\" In one respect , perhaps , Mr . Elton ' s manners are superior to Mr . Knightley ' s or Mr . Weston ' s .                                                                 0.505087\n",
      "\" Now ,\" said Emma , when they were fairly beyond the sweep gates , \" now Mr . Weston , do let me know what has happened .\"                                                 0.504980\n",
      "Emma found that it was not Mr . Weston ' s fault that the number of privy councillors was not yet larger .                                                                  0.504419\n",
      "\" I do not admire it ,\" said Mr . Knightley .                                                                                                                               0.499655\n",
      "Name: 1, dtype: float64\n",
      "Component 2: \n",
      "CHAPTER X       0.998811\n",
      "CHAPTER V       0.998811\n",
      "CHAPTER I       0.998811\n",
      "CHAPTER V       0.998811\n",
      "CHAPTER X       0.998811\n",
      "CHAPTER V       0.998811\n",
      "CHAPTER X       0.998811\n",
      "CHAPTER I       0.998811\n",
      "CHAPTER I       0.998811\n",
      "CHAPTER XIII    0.997865\n",
      "Name: 2, dtype: float64\n",
      "Component 3: \n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "\" Ah !    0.992917\n",
      "Name: 3, dtype: float64\n",
      "Component 4: \n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .    0.650510\n",
      "\" Are you well , my Emma ?\"                                                    0.598666\n",
      "Emma demurred .                                                                0.598666\n",
      "Emma was silenced .                                                            0.587465\n",
      "At first it was downright dulness to Emma .                                    0.586378\n",
      "\" Emma , my dear Emma \"                                                        0.576756\n",
      "Emma could not resist .                                                        0.567808\n",
      "\" It is not now worth a regret ,\" said Emma .                                  0.554384\n",
      "\" For shame , Emma !                                                           0.544590\n",
      "\" I am ready ,\" said Emma , \" whenever I am wanted .\"                          0.502204\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "paras_by_component = pd.DataFrame(X_train_lsa, index=X_train)\n",
    "for i in range(5):\n",
    "    print(\"Component {}: \".format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: \n",
      "0 That is _court_ .\n",
      "1 \" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"\n",
      "2 \" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .\n",
      "3 To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .\n",
      "4 Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .\n",
      "5 A very few minutes more , however , completed the present trial .\n",
      "6 \" I am delighted to hear you speak so stoutly on the subject ,\" replied Emma , smiling ; \" but you do not mean to deny that there was a time  and not very distant either  when you gave me reason to understand that you did care about him ?\"\n",
      "7 \" Very well ; and if he had intended to give her one , he would have told her so .\"\n",
      "8 Some laughed , and answered good - humouredly .\n",
      "9 \" There appeared such a perfectly good understanding among them all \" he began rather quickly , but checking himself , added , \" however , it is impossible for me to say on what terms they really were  how it might all be behind the scenes .\n"
     ]
    }
   ],
   "source": [
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "\n",
    "sim_matrix = pd.DataFrame(similarity, index=X_train).iloc[:10,:10]\n",
    "\n",
    "ax = sns.heatmap(sim_matrix, yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "print(\"Key: \")\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix3 = pd.DataFrame(similarity, index=X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"</th>\n",
       "      <td>0.244993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.052730</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.088750</td>\n",
       "      <td>-0.022005</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>-0.016459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>-0.061671</td>\n",
       "      <td>0.208425</td>\n",
       "      <td>0.026126</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.002934</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>-0.004262</td>\n",
       "      <td>-0.008388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Yes  I imagined  that is  I did not \"</th>\n",
       "      <td>0.288865</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>-0.020938</td>\n",
       "      <td>0.021524</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>-0.024227</td>\n",
       "      <td>0.168313</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.009023</td>\n",
       "      <td>-0.003224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>-0.030690</td>\n",
       "      <td>0.371616</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>-0.034446</td>\n",
       "      <td>-0.014962</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>-0.016792</td>\n",
       "      <td>-0.018359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Very well , I am much obliged to you .</th>\n",
       "      <td>0.040550</td>\n",
       "      <td>0.511181</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.054501</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>-0.031634</td>\n",
       "      <td>-0.030722</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>-0.026789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>-0.008498</td>\n",
       "      <td>-0.003464</td>\n",
       "      <td>0.059765</td>\n",
       "      <td>-0.016204</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.006375</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>-0.004396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.244993  1.000000   \n",
       "\" Yes  I imagined  that is  I did not \"             0.288865  0.527018   \n",
       "\" Very well , I am much obliged to you .            0.040550  0.511181   \n",
       "\n",
       "                                                        2         3     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.005713  0.052730   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.020938  0.021524   \n",
       "\" Very well , I am much obliged to you .            0.007937  0.054501   \n",
       "\n",
       "                                                        4         5     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.001338  0.019454   \n",
       "\" Yes  I imagined  that is  I did not \"             0.010301 -0.024227   \n",
       "\" Very well , I am much obliged to you .            0.009253  0.024070   \n",
       "\n",
       "                                                        6         7     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.088750 -0.022005   \n",
       "\" Yes  I imagined  that is  I did not \"             0.168313 -0.000687   \n",
       "\" Very well , I am much obliged to you .           -0.031634 -0.030722   \n",
       "\n",
       "                                                        8         9     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.019637 -0.016459   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.009023 -0.003224   \n",
       "\" Very well , I am much obliged to you .            0.030910 -0.026789   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...    ...    -0.003376   \n",
       "\" Yes  I imagined  that is  I did not \"               ...     0.003996   \n",
       "\" Very well , I am much obliged to you .              ...     0.017607   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.061671  0.208425   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.030690  0.371616   \n",
       "\" Very well , I am much obliged to you .           -0.008498 -0.003464   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.026126  0.010717   \n",
       "\" Yes  I imagined  that is  I did not \"             0.005773 -0.034446   \n",
       "\" Very well , I am much obliged to you .            0.059765 -0.016204   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.007071 -0.002934   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.014962 -0.007907   \n",
       "\" Very well , I am much obliged to you .            0.003427 -0.006375   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.011920 -0.004262   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.004561 -0.016792   \n",
       "\" Very well , I am much obliged to you .            0.000253  0.004478   \n",
       "\n",
       "                                                        1421  \n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.008388  \n",
       "\" Yes  I imagined  that is  I did not \"            -0.018359  \n",
       "\" Very well , I am much obliged to you .           -0.004396  \n",
       "\n",
       "[3 rows x 1422 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix3[sim_matrix3[1] > .5].sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .</th>\n",
       "      <td>-0.100339</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006241</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.076747</td>\n",
       "      <td>0.021734</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>-0.035867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>0.031995</td>\n",
       "      <td>-0.013675</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.034628</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>-0.049518</td>\n",
       "      <td>-0.044050</td>\n",
       "      <td>-0.021009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That is _ship_ ; plain as it can be . Now for the cream .</th>\n",
       "      <td>-0.094570</td>\n",
       "      <td>-0.015146</td>\n",
       "      <td>0.867604</td>\n",
       "      <td>0.072980</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>-0.015899</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>-0.004571</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>-0.008526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>-0.010117</td>\n",
       "      <td>-0.002965</td>\n",
       "      <td>-0.005161</td>\n",
       "      <td>-0.016030</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>-0.049642</td>\n",
       "      <td>-0.031307</td>\n",
       "      <td>-0.052882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" He is very plain , undoubtedly  remarkably plain : but that is nothing compared with his entire want of gentility .</th>\n",
       "      <td>-0.063073</td>\n",
       "      <td>-0.003166</td>\n",
       "      <td>0.826877</td>\n",
       "      <td>0.037426</td>\n",
       "      <td>-0.017431</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.036823</td>\n",
       "      <td>-0.026404</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055030</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>-0.015506</td>\n",
       "      <td>0.025941</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>-0.018858</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>-0.026495</td>\n",
       "      <td>-0.031875</td>\n",
       "      <td>-0.041613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" You speak too plain .</th>\n",
       "      <td>-0.099286</td>\n",
       "      <td>-0.006109</td>\n",
       "      <td>0.706247</td>\n",
       "      <td>0.172562</td>\n",
       "      <td>0.022725</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>-0.021710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>-0.031225</td>\n",
       "      <td>-0.010324</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>-0.026109</td>\n",
       "      <td>-0.007507</td>\n",
       "      <td>-0.044431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" My dear , you said that Miss Campbell would not allow him to be plain , and that you yourself \"</th>\n",
       "      <td>-0.025379</td>\n",
       "      <td>-0.024158</td>\n",
       "      <td>0.601242</td>\n",
       "      <td>0.059882</td>\n",
       "      <td>-0.005808</td>\n",
       "      <td>0.056027</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>-0.014559</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.016996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098983</td>\n",
       "      <td>-0.046985</td>\n",
       "      <td>-0.002489</td>\n",
       "      <td>-0.016198</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>-0.022667</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>-0.024812</td>\n",
       "      <td>-0.008566</td>\n",
       "      <td>-0.013328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" You are speaking of letters of business ; mine are letters of friendship .\"</th>\n",
       "      <td>-0.008878</td>\n",
       "      <td>0.082125</td>\n",
       "      <td>0.493096</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>0.097768</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.026387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>0.120335</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>-0.017185</td>\n",
       "      <td>-0.040115</td>\n",
       "      <td>-0.035698</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>-0.013485</td>\n",
       "      <td>0.044512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "\" How much his business engrosses him already i... -0.100339  0.005713   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.094570 -0.015146   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.063073 -0.003166   \n",
       "\" You speak too plain .                            -0.099286 -0.006109   \n",
       "\" My dear , you said that Miss Campbell would n... -0.025379 -0.024158   \n",
       "\" You are speaking of letters of business ; min... -0.008878  0.082125   \n",
       "\n",
       "                                                        2         3     \\\n",
       "\" How much his business engrosses him already i...  1.000000 -0.006241   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.867604  0.072980   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.826877  0.037426   \n",
       "\" You speak too plain .                             0.706247  0.172562   \n",
       "\" My dear , you said that Miss Campbell would n...  0.601242  0.059882   \n",
       "\" You are speaking of letters of business ; min...  0.493096  0.026545   \n",
       "\n",
       "                                                        4         5     \\\n",
       "\" How much his business engrosses him already i... -0.008564 -0.076747   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.005689 -0.015899   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.017431  0.004467   \n",
       "\" You speak too plain .                             0.022725  0.059251   \n",
       "\" My dear , you said that Miss Campbell would n... -0.005808  0.056027   \n",
       "\" You are speaking of letters of business ; min...  0.005407  0.005512   \n",
       "\n",
       "                                                        6         7     \\\n",
       "\" How much his business engrosses him already i...  0.021734  0.053773   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.059616 -0.004571   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.036823 -0.026404   \n",
       "\" You speak too plain .                             0.245211  0.012105   \n",
       "\" My dear , you said that Miss Campbell would n...  0.037256 -0.014559   \n",
       "\" You are speaking of letters of business ; min...  0.013816  0.097768   \n",
       "\n",
       "                                                        8         9     \\\n",
       "\" How much his business engrosses him already i...  0.007574 -0.035867   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.020094 -0.008526   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.007565  0.014585   \n",
       "\" You speak too plain .                             0.015839 -0.021710   \n",
       "\" My dear , you said that Miss Campbell would n... -0.000890 -0.016996   \n",
       "\" You are speaking of letters of business ; min...  0.007370  0.026387   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "\" How much his business engrosses him already i...    ...     0.015581   \n",
       "That is _ship_ ; plain as it can be . Now for t...    ...     0.054286   \n",
       "\" He is very plain , undoubtedly  remarkably pl...    ...     0.055030   \n",
       "\" You speak too plain .                               ...     0.048828   \n",
       "\" My dear , you said that Miss Campbell would n...    ...     0.098983   \n",
       "\" You are speaking of letters of business ; min...    ...     0.038226   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "\" How much his business engrosses him already i...  0.031995 -0.013675   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.010117 -0.002965   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.022615 -0.015506   \n",
       "\" You speak too plain .                            -0.031225 -0.010324   \n",
       "\" My dear , you said that Miss Campbell would n... -0.046985 -0.002489   \n",
       "\" You are speaking of letters of business ; min...  0.120335 -0.008439   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "\" How much his business engrosses him already i...  0.011034  0.003325   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.005161 -0.016030   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.025941 -0.021328   \n",
       "\" You speak too plain .                             0.002086  0.000821   \n",
       "\" My dear , you said that Miss Campbell would n... -0.016198  0.012815   \n",
       "\" You are speaking of letters of business ; min...  0.049642 -0.017185   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "\" How much his business engrosses him already i... -0.034628  0.005863   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.025731  0.010167   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.018858  0.015318   \n",
       "\" You speak too plain .                            -0.012478  0.022552   \n",
       "\" My dear , you said that Miss Campbell would n... -0.022667  0.116772   \n",
       "\" You are speaking of letters of business ; min... -0.040115 -0.035698   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "\" How much his business engrosses him already i... -0.049518 -0.044050   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.049642 -0.031307   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.026495 -0.031875   \n",
       "\" You speak too plain .                            -0.026109 -0.007507   \n",
       "\" My dear , you said that Miss Campbell would n... -0.024812 -0.008566   \n",
       "\" You are speaking of letters of business ; min...  0.003938 -0.013485   \n",
       "\n",
       "                                                        1421  \n",
       "\" How much his business engrosses him already i... -0.021009  \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.052882  \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.041613  \n",
       "\" You speak too plain .                            -0.044431  \n",
       "\" My dear , you said that Miss Campbell would n... -0.013328  \n",
       "\" You are speaking of letters of business ; min...  0.044512  \n",
       "\n",
       "[6 rows x 1422 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix3[sim_matrix3[2] > .47].sort_values(2, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .</th>\n",
       "      <td>0.030975</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.039977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.110660</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>0.077220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183178</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>0.024701</td>\n",
       "      <td>0.019653</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.037288</td>\n",
       "      <td>-0.034865</td>\n",
       "      <td>0.017279</td>\n",
       "      <td>-0.018750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" I have some hope ,\" resumed he , \" of my uncle ' s being persuaded to pay a visit at Randalls ; he wants to be introduced to her .</th>\n",
       "      <td>0.067962</td>\n",
       "      <td>0.027645</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>0.027328</td>\n",
       "      <td>0.663567</td>\n",
       "      <td>0.052686</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179137</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>-0.028640</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-0.002430</td>\n",
       "      <td>-0.054857</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.030975  0.001338   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.067962  0.027645   \n",
       "\n",
       "                                                        2         3     \\\n",
       "Emma smiled and answered \" My visit was of use ... -0.008564 -0.039977   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.004650  0.027328   \n",
       "\n",
       "                                                        4         5     \\\n",
       "Emma smiled and answered \" My visit was of use ...  1.000000  0.005526   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.663567  0.052686   \n",
       "\n",
       "                                                        6         7     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.048726  0.110660   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.020249  0.092683   \n",
       "\n",
       "                                                        8         9     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.272820  0.077220   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.021885  0.011978   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "Emma smiled and answered \" My visit was of use ...    ...     0.183178   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...    ...     0.179137   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.206600  0.019884   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.047419 -0.017571   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.024701  0.019653   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.028640  0.000150   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.005605  0.037288   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.013073 -0.002430   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "Emma smiled and answered \" My visit was of use ... -0.034865  0.017279   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.054857  0.033995   \n",
       "\n",
       "                                                        1421  \n",
       "Emma smiled and answered \" My visit was of use ... -0.018750  \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.003086  \n",
       "\n",
       "[2 rows x 1422 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix3[sim_matrix3[4] > .5].sort_values(4, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>max_df is .7 and min_df is 5</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(emma_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.7, min_df=5,\n",
    "                            stop_words=\"english\",\n",
    "                            lowercase=True,\n",
    "                            use_idf=True,\n",
    "                            norm=u\"l2\",\n",
    "                            smooth_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 799\n"
     ]
    }
   ],
   "source": [
    "emma_paras_tfidf = vectorizer.fit_transform(emma_paras)\n",
    "print(\"Number of features: %d\" % emma_paras_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf= train_test_split(emma_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentenct: A very few minutes more , however , completed the present trial .\n",
      "Tf_idf vector: {'minutes': 0.7127450310382584, 'present': 0.701423210857947}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sentenct:\", X_train[5])\n",
    "print(\"Tf_idf vector:\", tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components 55.90542638089724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained = svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "\n",
    "print(\"Percent variance captured by all components\", total_variance*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0: \n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !\"    0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "\" Oh !     0.999068\n",
      "Name: 0, dtype: float64\n",
      "Component 1: \n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                                                                                0.708431\n",
      "\" You get upon delicate subjects , Emma ,\" said Mrs . Weston smiling ; \" remember that I am here . Mr .                                                                     0.616767\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                                                                                           0.615467\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .                                                                                                 0.608388\n",
      "Emma found that it was not Mr . Weston ' s fault that the number of privy councillors was not yet larger .                                                                  0.583912\n",
      "\" Emma ,\" said Mr . Knightley presently , \" I have a piece of news for you .                                                                                                0.570218\n",
      "Emma could not have desired a more spirited rejection of Mr . Martin ' s prose .                                                                                            0.564632\n",
      "\" I do not know what your opinion may be , Mrs . Weston ,\" said Mr . Knightley , \" of this great intimacy between Emma and Harriet Smith , but I think it a bad thing .\"    0.559653\n",
      "\" It is not now worth a regret ,\" said Emma .                                                                                                                               0.549407\n",
      "\" Now ,\" said Emma , when they were fairly beyond the sweep gates , \" now Mr . Weston , do let me know what has happened .\"                                                 0.549011\n",
      "Name: 1, dtype: float64\n",
      "Component 2: \n",
      "CHAPTER XII     1.0\n",
      "CHAPTER X       1.0\n",
      "CHAPTER VIII    1.0\n",
      "CHAPTER XI      1.0\n",
      "CHAPTER VII     1.0\n",
      "CHAPTER II      1.0\n",
      "CHAPTER IV      1.0\n",
      "CHAPTER XVI     1.0\n",
      "CHAPTER II      1.0\n",
      "CHAPTER XI      1.0\n",
      "Name: 2, dtype: float64\n",
      "Component 3: \n",
      "\" For shame , Emma !                                                           0.674147\n",
      "\" Are you well , my Emma ?\"                                                    0.674147\n",
      "Emma was silenced .                                                            0.674147\n",
      "At first it was downright dulness to Emma .                                    0.674147\n",
      "Emma demurred .                                                                0.674147\n",
      "Emma could not resist .                                                        0.674147\n",
      "Emma was most sincerely interested .                                           0.616763\n",
      "\" Emma , my dear Emma \"                                                        0.601304\n",
      "Emma was out of hearing .                                                      0.573452\n",
      "\" There were misunderstandings between them , Emma ; he said so expressly .    0.567323\n",
      "Name: 3, dtype: float64\n",
      "Component 4: \n",
      "\" Mr . Knightley was there too , was he ?\"                                                                     0.590183\n",
      "Mr . Knightley might quarrel with her , but Emma could not quarrel with herself .                              0.564951\n",
      "\"` Mr .                                                                                                        0.538718\n",
      "Mr . Knightley grew angry .                                                                                    0.500759\n",
      "\" I do not admire it ,\" said Mr . Knightley .                                                                  0.490604\n",
      "\" You have made her too tall , Emma ,\" said Mr . Knightley .                                                   0.489237\n",
      "\" In one respect , perhaps , Mr . Elton ' s manners are superior to Mr . Knightley ' s or Mr . Weston ' s .    0.467417\n",
      "Mr . Knightley , however , shewed no triumphant happiness .                                                    0.463462\n",
      "While waiting for the carriage , she found Mr . Knightley by her side .                                        0.461314\n",
      "Mr . Knightley had done all in his power for Mr . Woodhouse ' s entertainment .                                0.458077\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "paras_by_component = pd.DataFrame(X_train_lsa, index=X_train)\n",
    "for i in range(5):\n",
    "    print(\"Component {}: \".format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: \n",
      "0 That is _court_ .\n",
      "1 \" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"\n",
      "2 \" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .\n",
      "3 To restrain him as much as might be , by her own manners , she was immediately preparing to speak with exquisite calmness and gravity of the weather and the night ; but scarcely had she begun , scarcely had they passed the sweep - gate and joined the other carriage , than she found her subject cut up  her hand seized  her attention demanded , and Mr . Elton actually making violent love to her : availing himself of the precious opportunity , declaring sentiments which must be already well known , hoping  fearing  adoring  ready to die if she refused him ; but flattering himself that his ardent attachment and unequalled love and unexampled passion could not fail of having some effect , and in short , very much resolved on being seriously accepted as soon as possible .\n",
      "4 Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .\n",
      "5 A very few minutes more , however , completed the present trial .\n",
      "6 \" I am delighted to hear you speak so stoutly on the subject ,\" replied Emma , smiling ; \" but you do not mean to deny that there was a time  and not very distant either  when you gave me reason to understand that you did care about him ?\"\n",
      "7 \" Very well ; and if he had intended to give her one , he would have told her so .\"\n",
      "8 Some laughed , and answered good - humouredly .\n",
      "9 \" There appeared such a perfectly good understanding among them all \" he began rather quickly , but checking himself , added , \" however , it is impossible for me to say on what terms they really were  how it might all be behind the scenes .\n"
     ]
    }
   ],
   "source": [
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "\n",
    "sim_matrix = pd.DataFrame(similarity, index=X_train).iloc[:10,:10]\n",
    "\n",
    "ax = sns.heatmap(sim_matrix, yticklabels=range(10))\n",
    "plt.show()\n",
    "\n",
    "print(\"Key: \")\n",
    "for i in range(10):\n",
    "    print(i,sim_matrix.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix4 = pd.DataFrame(similarity, index=X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" Yes , sir , I did indeed ; and I am very much obliged by your kind solicitude about me .\"</th>\n",
       "      <td>0.048987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013773</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>-0.007079</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006596</td>\n",
       "      <td>-0.053907</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>-0.036344</td>\n",
       "      <td>-0.014327</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Yes  I imagined  that is  I did not \"</th>\n",
       "      <td>0.042533</td>\n",
       "      <td>0.568888</td>\n",
       "      <td>-0.045833</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>-0.008666</td>\n",
       "      <td>0.187277</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>-0.002691</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.388587</td>\n",
       "      <td>0.013085</td>\n",
       "      <td>-0.016519</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.005972</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>-0.015779</td>\n",
       "      <td>-0.010486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" Very well , I am much obliged to you .</th>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.514689</td>\n",
       "      <td>-0.004534</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>-0.020584</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.041112</td>\n",
       "      <td>-0.017681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>-0.012355</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>-0.022378</td>\n",
       "      <td>-0.026317</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.048987  1.000000   \n",
       "\" Yes  I imagined  that is  I did not \"             0.042533  0.568888   \n",
       "\" Very well , I am much obliged to you .            0.008095  0.514689   \n",
       "\n",
       "                                                        2         3     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.013773  0.025816   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.045833  0.017930   \n",
       "\" Very well , I am much obliged to you .           -0.004534  0.009097   \n",
       "\n",
       "                                                        4         5     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.001684 -0.007079   \n",
       "\" Yes  I imagined  that is  I did not \"             0.004169 -0.008666   \n",
       "\" Very well , I am much obliged to you .            0.002946  0.013156   \n",
       "\n",
       "                                                        6         7     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.099934  0.010875   \n",
       "\" Yes  I imagined  that is  I did not \"             0.187277  0.004935   \n",
       "\" Very well , I am much obliged to you .           -0.020584  0.009033   \n",
       "\n",
       "                                                        8         9     \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.006139 -0.000728   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.002691 -0.003231   \n",
       "\" Very well , I am much obliged to you .            0.041112 -0.017681   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...    ...    -0.006596   \n",
       "\" Yes  I imagined  that is  I did not \"               ...     0.021965   \n",
       "\" Very well , I am much obliged to you .              ...     0.001622   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.053907  0.251572   \n",
       "\" Yes  I imagined  that is  I did not \"             0.004203  0.388587   \n",
       "\" Very well , I am much obliged to you .           -0.012355  0.010988   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.036344 -0.014327   \n",
       "\" Yes  I imagined  that is  I did not \"             0.013085 -0.016519   \n",
       "\" Very well , I am much obliged to you .           -0.022378 -0.026317   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much... -0.001119 -0.001024   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.013812 -0.005972   \n",
       "\" Very well , I am much obliged to you .            0.005857  0.004604   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.004189 -0.003584   \n",
       "\" Yes  I imagined  that is  I did not \"            -0.003291 -0.015779   \n",
       "\" Very well , I am much obliged to you .            0.000699  0.002249   \n",
       "\n",
       "                                                        1421  \n",
       "\" Yes , sir , I did indeed ; and I am very much...  0.003235  \n",
       "\" Yes  I imagined  that is  I did not \"            -0.010486  \n",
       "\" Very well , I am much obliged to you .            0.011659  \n",
       "\n",
       "[3 rows x 1422 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix4[sim_matrix4[1] > .5].sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\" How much his business engrosses him already is very plain from the circumstance of his forgetting to inquire for the book you recommended .</th>\n",
       "      <td>-0.049823</td>\n",
       "      <td>-0.013773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039616</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>-0.112840</td>\n",
       "      <td>0.049603</td>\n",
       "      <td>-0.107253</td>\n",
       "      <td>-0.002767</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022538</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.007377</td>\n",
       "      <td>-0.020318</td>\n",
       "      <td>-0.028311</td>\n",
       "      <td>-0.019123</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>-0.021906</td>\n",
       "      <td>0.037289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>That is _ship_ ; plain as it can be . Now for the cream .</th>\n",
       "      <td>-0.059744</td>\n",
       "      <td>-0.042360</td>\n",
       "      <td>0.815240</td>\n",
       "      <td>0.096530</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>-0.015087</td>\n",
       "      <td>0.109017</td>\n",
       "      <td>-0.075652</td>\n",
       "      <td>-0.017304</td>\n",
       "      <td>0.048278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>-0.020438</td>\n",
       "      <td>-0.072751</td>\n",
       "      <td>-0.011694</td>\n",
       "      <td>-0.013485</td>\n",
       "      <td>0.012364</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>0.005684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" He is very plain , undoubtedly  remarkably plain : but that is nothing compared with his entire want of gentility .</th>\n",
       "      <td>-0.060971</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.779464</td>\n",
       "      <td>0.077449</td>\n",
       "      <td>-0.027872</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.077208</td>\n",
       "      <td>-0.027928</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083127</td>\n",
       "      <td>0.057068</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>-0.075801</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>-0.023013</td>\n",
       "      <td>-0.001287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" You speak too plain .</th>\n",
       "      <td>-0.029534</td>\n",
       "      <td>-0.029626</td>\n",
       "      <td>0.689159</td>\n",
       "      <td>0.195203</td>\n",
       "      <td>0.041298</td>\n",
       "      <td>0.060578</td>\n",
       "      <td>0.245665</td>\n",
       "      <td>-0.043541</td>\n",
       "      <td>-0.015962</td>\n",
       "      <td>0.034639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>-0.044893</td>\n",
       "      <td>-0.054873</td>\n",
       "      <td>-0.005273</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>-0.012018</td>\n",
       "      <td>0.021048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" My dear , you said that Miss Campbell would not allow him to be plain , and that you yourself \"</th>\n",
       "      <td>0.071946</td>\n",
       "      <td>-0.043312</td>\n",
       "      <td>0.521131</td>\n",
       "      <td>0.029758</td>\n",
       "      <td>-0.018280</td>\n",
       "      <td>0.067456</td>\n",
       "      <td>0.090182</td>\n",
       "      <td>-0.027482</td>\n",
       "      <td>-0.014422</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094129</td>\n",
       "      <td>-0.051718</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>-0.019305</td>\n",
       "      <td>-0.022749</td>\n",
       "      <td>-0.022081</td>\n",
       "      <td>0.113836</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>0.015668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emma could not forgive her ; but as neither provocation nor resentment were discerned by Mr . Knightley , who had been of the party , and had seen only proper attention and pleasing behaviour on each side , he was expressing the next morning , being at Hartfield again on business with Mr . Woodhouse , his approbation of the whole ; not so openly as he might have done had her father been out of the room , but speaking plain enough to be very intelligible to Emma .</th>\n",
       "      <td>0.093224</td>\n",
       "      <td>-0.006300</td>\n",
       "      <td>0.475304</td>\n",
       "      <td>0.118376</td>\n",
       "      <td>0.072437</td>\n",
       "      <td>-0.071336</td>\n",
       "      <td>0.066234</td>\n",
       "      <td>-0.145289</td>\n",
       "      <td>-0.074492</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080181</td>\n",
       "      <td>0.166009</td>\n",
       "      <td>-0.012012</td>\n",
       "      <td>0.099116</td>\n",
       "      <td>0.078894</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>0.017457</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.269396</td>\n",
       "      <td>0.012381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "\" How much his business engrosses him already i... -0.049823 -0.013773   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.059744 -0.042360   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.060971 -0.029728   \n",
       "\" You speak too plain .                            -0.029534 -0.029626   \n",
       "\" My dear , you said that Miss Campbell would n...  0.071946 -0.043312   \n",
       "Emma could not forgive her ; but as neither pro...  0.093224 -0.006300   \n",
       "\n",
       "                                                        2         3     \\\n",
       "\" How much his business engrosses him already i...  1.000000  0.039616   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.815240  0.096530   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.779464  0.077449   \n",
       "\" You speak too plain .                             0.689159  0.195203   \n",
       "\" My dear , you said that Miss Campbell would n...  0.521131  0.029758   \n",
       "Emma could not forgive her ; but as neither pro...  0.475304  0.118376   \n",
       "\n",
       "                                                        4         5     \\\n",
       "\" How much his business engrosses him already i...  0.017635 -0.112840   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.006793 -0.015087   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.027872  0.001592   \n",
       "\" You speak too plain .                             0.041298  0.060578   \n",
       "\" My dear , you said that Miss Campbell would n... -0.018280  0.067456   \n",
       "Emma could not forgive her ; but as neither pro...  0.072437 -0.071336   \n",
       "\n",
       "                                                        6         7     \\\n",
       "\" How much his business engrosses him already i...  0.049603 -0.107253   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.109017 -0.075652   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.087753 -0.077208   \n",
       "\" You speak too plain .                             0.245665 -0.043541   \n",
       "\" My dear , you said that Miss Campbell would n...  0.090182 -0.027482   \n",
       "Emma could not forgive her ; but as neither pro...  0.066234 -0.145289   \n",
       "\n",
       "                                                        8         9     \\\n",
       "\" How much his business engrosses him already i... -0.002767  0.052060   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.017304  0.048278   \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.027928  0.077145   \n",
       "\" You speak too plain .                            -0.015962  0.034639   \n",
       "\" My dear , you said that Miss Campbell would n... -0.014422  0.009800   \n",
       "Emma could not forgive her ; but as neither pro... -0.074492  0.005336   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "\" How much his business engrosses him already i...    ...    -0.022538   \n",
       "That is _ship_ ; plain as it can be . Now for t...    ...     0.049390   \n",
       "\" He is very plain , undoubtedly  remarkably pl...    ...     0.083127   \n",
       "\" You speak too plain .                               ...     0.036014   \n",
       "\" My dear , you said that Miss Campbell would n...    ...     0.094129   \n",
       "Emma could not forgive her ; but as neither pro...    ...     0.080181   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "\" How much his business engrosses him already i... -0.010228 -0.007377   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.002990  0.020700   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.057068  0.014297   \n",
       "\" You speak too plain .                             0.014658  0.017900   \n",
       "\" My dear , you said that Miss Campbell would n... -0.051718  0.020038   \n",
       "Emma could not forgive her ; but as neither pro...  0.166009 -0.012012   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "\" How much his business engrosses him already i... -0.020318 -0.028311   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.020438 -0.072751   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.032176 -0.075801   \n",
       "\" You speak too plain .                            -0.044893 -0.054873   \n",
       "\" My dear , you said that Miss Campbell would n... -0.019305 -0.022749   \n",
       "Emma could not forgive her ; but as neither pro...  0.099116  0.078894   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "\" How much his business engrosses him already i... -0.019123  0.010410   \n",
       "That is _ship_ ; plain as it can be . Now for t... -0.011694 -0.013485   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.009298 -0.020380   \n",
       "\" You speak too plain .                            -0.005273  0.001497   \n",
       "\" My dear , you said that Miss Campbell would n... -0.022081  0.113836   \n",
       "Emma could not forgive her ; but as neither pro... -0.006584  0.017457   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "\" How much his business engrosses him already i...  0.001573 -0.021906   \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.012364 -0.004557   \n",
       "\" He is very plain , undoubtedly  remarkably pl...  0.029150 -0.023013   \n",
       "\" You speak too plain .                            -0.002304 -0.012018   \n",
       "\" My dear , you said that Miss Campbell would n...  0.014972  0.032101   \n",
       "Emma could not forgive her ; but as neither pro...  0.002000  0.269396   \n",
       "\n",
       "                                                        1421  \n",
       "\" How much his business engrosses him already i...  0.037289  \n",
       "That is _ship_ ; plain as it can be . Now for t...  0.005684  \n",
       "\" He is very plain , undoubtedly  remarkably pl... -0.001287  \n",
       "\" You speak too plain .                             0.021048  \n",
       "\" My dear , you said that Miss Campbell would n...  0.015668  \n",
       "Emma could not forgive her ; but as neither pro...  0.012381  \n",
       "\n",
       "[6 rows x 1422 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix4[sim_matrix4[2] > .47].sort_values(2, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1412</th>\n",
       "      <th>1413</th>\n",
       "      <th>1414</th>\n",
       "      <th>1415</th>\n",
       "      <th>1416</th>\n",
       "      <th>1417</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Emma smiled and answered \" My visit was of use to the nervous part of her complaint , I hope ; but not even I can charm away a sore throat ; it is a most severe cold indeed .</th>\n",
       "      <td>0.067404</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.104807</td>\n",
       "      <td>0.109494</td>\n",
       "      <td>0.199750</td>\n",
       "      <td>0.281972</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159076</td>\n",
       "      <td>0.284271</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>0.048651</td>\n",
       "      <td>-0.008348</td>\n",
       "      <td>0.040788</td>\n",
       "      <td>-0.021704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\" I have some hope ,\" resumed he , \" of my uncle ' s being persuaded to pay a visit at Randalls ; he wants to be introduced to her .</th>\n",
       "      <td>-0.000777</td>\n",
       "      <td>0.032478</td>\n",
       "      <td>-0.026677</td>\n",
       "      <td>0.039928</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>-0.037485</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>0.139613</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>-0.033585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237171</td>\n",
       "      <td>0.167043</td>\n",
       "      <td>-0.006310</td>\n",
       "      <td>0.032754</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>-0.026654</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-0.031860</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>-0.035443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  1422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.067404 -0.001684   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.000777  0.032478   \n",
       "\n",
       "                                                        2         3     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.017635 -0.000663   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.026677  0.039928   \n",
       "\n",
       "                                                        4         5     \\\n",
       "Emma smiled and answered \" My visit was of use ...  1.000000 -0.104807   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.595588 -0.037485   \n",
       "\n",
       "                                                        6         7     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.109494  0.199750   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.021801  0.139613   \n",
       "\n",
       "                                                        8         9     \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.281972  0.023769   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.021641 -0.033585   \n",
       "\n",
       "                                                      ...         1412  \\\n",
       "Emma smiled and answered \" My visit was of use ...    ...     0.159076   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...    ...     0.237171   \n",
       "\n",
       "                                                        1413      1414  \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.284271  0.005071   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.167043 -0.006310   \n",
       "\n",
       "                                                        1415      1416  \\\n",
       "Emma smiled and answered \" My visit was of use ...  0.020647  0.002641   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl...  0.032754  0.003859   \n",
       "\n",
       "                                                        1417      1418  \\\n",
       "Emma smiled and answered \" My visit was of use ... -0.003251  0.048651   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.026654 -0.018284   \n",
       "\n",
       "                                                        1419      1420  \\\n",
       "Emma smiled and answered \" My visit was of use ... -0.008348  0.040788   \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.031860 -0.002446   \n",
       "\n",
       "                                                        1421  \n",
       "Emma smiled and answered \" My visit was of use ... -0.021704  \n",
       "\" I have some hope ,\" resumed he , \" of my uncl... -0.035443  \n",
       "\n",
       "[2 rows x 1422 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix4[sim_matrix4[4] > .5].sort_values(4, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** The similarity of sentences was not incredibly different with different max_df and min_df. The slightly more effective max_df is .7 and the min_df is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

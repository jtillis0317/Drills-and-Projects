{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\jesst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jesst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())\n",
    "\n",
    "persuasion = gutenberg.raw(\"austen-persuasion.txt\")\n",
    "alice = gutenberg.raw(\"carroll-alice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw:\n",
      " [Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRaw:\\n\", alice[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title removed:\n",
      " \n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on\n"
     ]
    }
   ],
   "source": [
    "pattern = \"[\\[].*?[\\]]\"\n",
    "persuasion = re.sub(pattern, \"\", persuasion)\n",
    "alice = re.sub(pattern, \"\", alice)\n",
    "\n",
    "print(\"Title removed:\\n\", alice[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter headings removed:\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothin\n"
     ]
    }
   ],
   "source": [
    "persuasion = re.sub(r\"Chapter \\d+\", \"\", persuasion)\n",
    "alice = re.sub(r\"CHAPTER .*\", \"\", alice)\n",
    "\n",
    "print(\"Chapter headings removed:\\n\", alice[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra whitespace removed:\n",
      " Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to\n"
     ]
    }
   ],
   "source": [
    "persuasion = \" \".join(persuasion.split())\n",
    "alice = \" \".join(alice.split())\n",
    "\n",
    "print(\"Extra whitespace removed:\\n\", alice[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alice_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
      "It is 34430 tokens long.\n",
      "The first three tokens are 'Alice was beginning'\n",
      "The type of each token is <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The alice_doc object is a {} object.\".format(type(alice_doc)))\n",
    "print(\"It is {} tokens long.\".format(len(alice_doc)))\n",
    "print(\"The first three tokens are '{}'\".format(alice_doc[:3]))\n",
    "print(\"The type of each token is {}\".format(type(alice_doc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice: [('the', 1524), ('and', 796), ('to', 724), ('a', 611), ('I', 534), ('it', 524), ('she', 508), ('of', 499), ('said', 453), ('Alice', 394)]\n",
      "Persuasion: [('the', 3120), ('to', 2775), ('and', 2738), ('of', 2563), ('a', 1529), ('in', 1346), ('was', 1329), ('had', 1177), ('her', 1159), ('I', 1121)]\n"
     ]
    }
   ],
   "source": [
    "def word_frequencies(text, include_stop=True):\n",
    "    words = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            words.append(token.text)\n",
    "            \n",
    "    return Counter(words)\n",
    "\n",
    "alice_freq = word_frequencies(alice_doc).most_common(10)\n",
    "persuasion_freq = word_frequencies(persuasion_doc).most_common(10)\n",
    "print(\"Alice:\", alice_freq)\n",
    "print(\"Persuasion:\", persuasion_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice: [('I', 534), ('said', 453), ('Alice', 394), (\"n't\", 215), (\"'s\", 190), ('little', 124), ('The', 102), ('like', 84), ('went', 83), ('know', 83)]\n",
      "Persuasion: [('I', 1121), ('Anne', 497), (\"'s\", 485), ('She', 326), ('Captain', 297), ('Mrs', 291), ('Elliot', 288), ('Mr', 255), ('He', 225), ('Wentworth', 217)]\n"
     ]
    }
   ],
   "source": [
    "alice_freq = word_frequencies(alice_doc, include_stop=False).most_common(10)\n",
    "persuasion_freq = word_frequencies(persuasion_doc, include_stop=False).most_common(10)\n",
    "print(\"Alice:\", alice_freq)\n",
    "print(\"Persuasion:\", persuasion_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique to Alice: {'The', 'went', 'know', 'like', \"n't\", 'Alice', 'said', 'little'}\n",
      "Unique to Persuasion: {'He', 'She', 'Elliot', 'Wentworth', 'Anne', 'Captain', 'Mr', 'Mrs'}\n"
     ]
    }
   ],
   "source": [
    "alice_common = [pair[0] for pair in alice_freq]\n",
    "persuasion_common = [pair[0] for pair in persuasion_freq]\n",
    "\n",
    "print(\"Unique to Alice:\", set(alice_common) - set(persuasion_common))\n",
    "print(\"Unique to Persuasion:\", set(persuasion_common) - set(alice_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'said', 'Alice', \"n't\", \"'s\", 'little', 'The', 'like', 'went', 'know']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pair[0] for pair in alice_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_frequencies(text, include_stop=True):\n",
    "    lemmas = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alice: [('-PRON-', 758), ('say', 476), ('alice', 396), ('be', 254), ('not', 231), ('go', 133), ('think', 131), ('little', 126), ('the', 109), ('look', 105)]\n",
      "Persuasion: [('-PRON-', 2241), ('anne', 497), (\"'s\", 466), ('captain', 303), ('elliot', 295), ('mrs', 291), ('good', 289), ('know', 258), ('think', 256), ('mr', 255)]\n"
     ]
    }
   ],
   "source": [
    "alice_lemma_freq = lemma_frequencies(alice_doc, include_stop=False).most_common(10)\n",
    "persuasion_lemma_freq = lemma_frequencies(persuasion_doc, include_stop=False).most_common(10)\n",
    "\n",
    "print(\"\\nAlice:\", alice_lemma_freq)\n",
    "print(\"Persuasion:\", persuasion_lemma_freq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique to Alice: {'be', 'look', 'go', 'not', 'alice', 'little', 'the', 'say'}\n",
      "Unique to Persuasion: {'know', \"'s\", 'mr', 'anne', 'captain', 'mrs', 'good', 'elliot'}\n"
     ]
    }
   ],
   "source": [
    "alice_lemma_common = [pair[0] for pair in alice_lemma_freq]\n",
    "persuasion_lemma_common = [pair[0] for pair in persuasion_lemma_freq]\n",
    "print(\"Unique to Alice:\", set(alice_lemma_common) - set(persuasion_lemma_common))\n",
    "print(\"Unique to Persuasion:\", set(persuasion_lemma_common) - set(alice_lemma_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice in Wonderland has 1678 sentences.\n",
      "Here is an example: \n",
      "There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = list(alice_doc.sents)\n",
    "print(\"Alice in Wonderland has {} sentences.\".format(len(sentences)))\n",
    "\n",
    "example_sentence = sentences[2]\n",
    "print(\"Here is an example: \\n{}\\n\".format(example_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"I want a hippopotamus\")[1].pos_)\n",
    "print(nlp(\"I have several wants\")[3].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There was nothing so VERY remarkable in that; nor"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parts of Speech:\n",
      "There ADV\n",
      "was VERB\n",
      "nothing NOUN\n",
      "so ADV\n",
      "VERY ADV\n",
      "remarkable ADJ\n",
      "in ADP\n",
      "that DET\n",
      "; PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nParts of Speech:\")\n",
    "for token in example_sentence[:9]:\n",
    "    print(token.orth_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies:\n",
      "There expl was\n",
      "was ROOT was\n",
      "nothing attr was\n",
      "so advmod remarkable\n",
      "VERY advmod remarkable\n",
      "remarkable amod nothing\n",
      "in prep nothing\n",
      "that pobj in\n",
      "; punct was\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDependencies:\")\n",
    "for token in example_sentence[:9]:\n",
    "    print(token.orth_, token.dep_, token.head.orth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON Alice\n",
      "DATE the hot day\n",
      "PERSON Alice\n",
      "PRODUCT Rabbit\n",
      "PRODUCT Rabbit\n",
      "PRODUCT WAISTCOAT - POCKET\n",
      "PERSON Alice\n",
      "PERSON Alice\n",
      "PERSON Alice\n",
      "ORDINAL First\n"
     ]
    }
   ],
   "source": [
    "entities = list(alice_doc.ents)[0:10]\n",
    "for entity in entities:\n",
    "    print(entity.label_, \" \".join(t.orth_ for t in entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"the Mock Turtle: '\", 'The White Rabbit', 'Gryphon', 'Begin', 'M--', 'Prizes', 'Fish-Footman', 'indeed:--', 'Soup', 'Mary Ann', 'Canary', 'Shakespeare', 'Run', 'Shall', 'Beau', 'the Mock Turtle', 'INSIDE', 'Edgar Atheling', 'Sentence', 'HAD', 'Mabel', 'The Fish-Footman', 'Turn', 'Hush', 'Mock Turtle', 'Elsie', \"Don't\", 'a Lobster Quadrille', 'Idiot', 'the March Hare', 'the Lobster Quadrille?', 'the King', 'Frog-Footman', 'Fifteenth', 'Bill', 'Panther', 'Sixteenth', '--or', 'Morcar', 'Serpent', 'The Queen', 'Said', 'Rabbit', 'Beautiful Soup', 'm--', 'Soles', 'FUL SOUP', 'Latitude', 'Seaography', 'Crab', 'Stolen', 'Lacie', 'Adventures', 'Pat', 'Drink', 'Ma', 'Duchess', 'Cheshire Puss', 'YOURS', 'The Mock Turtle', 'Pinch', \"Dinah'll\", 'Brandy', 'Tut', 'William the Conqueror', 'Tillie', 'Fury', 'William', \"the Duchess: '\", 'Jack', 'Treacle', 'Stupid', 'Repeat', \"the King: '\", 'WILLIAM', 'Duck', 'the Queen of Hearts', 'Ou', 'the Duchess', 'Queen', 'Alice', 'Longitude', 'Majesty', 'Kings', 'Turtle Soup', 'Soo', 'Edwin', 'Curiouser', 'Soup of the evening', 'the Lobster Quadrille', 'the White Rabbit', 'Latin Grammar', 'Sha', 'Hjckrrh', 'began:--', 'Stand', 'Down', 'Footman', 'this:--', 'Shy', 'Fetch'}\n"
     ]
    }
   ],
   "source": [
    "people = [entity.text for entity in list(alice_doc.ents) if entity.label_ == \"PERSON\"]\n",
    "print(set(people))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
